<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>🏠Home on </title>
    <link>/</link>
    <description>Recent content in 🏠Home on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>00. Great Debate</title>
      <link>/01-excel/activities/day-01/00-great-debate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-01/00-great-debate/</guid>
      <description>Thought Experiment #1 &amp;ldquo;Which food do Americans prefer: Italian food or Mexican food?&amp;rdquo; The task is to develop a strategy for answering this question in 10 hours or less, using data. Note: Have fun! Slides Click here for 1.1 Slides that has the prompt as well</description>
    </item>
    
    <item>
      <title>00. Setup for Mac and PC 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-01/00-setup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/00-setup/</guid>
      <description>Installing pgAdmin and Postgres on a Mac Similar to coding with Python using Visual Studio Code, SQL requires a code editor with the ability to execute the scripts that are created by developers. This section guides you through the process of installing pgAdmin and Postgres on a Mac.
Before You Begin   Remember to choose the installation package specific to your operating system and download the latest version.
  Be prepared to record a password—it will be needed later!</description>
    </item>
    
    <item>
      <title>01. </title>
      <link>/10-advanced-sql/activities/day-03/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/01/</guid>
      <description></description>
    </item>
    
    <item>
      <title>01.  Jupyter Intro 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-01/01-jupyter-intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/01-jupyter-intro/</guid>
      <description> # Running the basic &amp;#34;Hello World&amp;#34; code hello = &amp;#34;Hello World&amp;#34; print(hello) Hello World  # Doing simple math 4 + 4 8  # Storing results in variables a = 5  # Using those variables elsewhere in the code a 5   # Variables will hold the value most recently run # This means that, if we run the code above, it will now print 2 a = 2 </description>
    </item>
    
    <item>
      <title>01.  Merging 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-03/01-merging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-03/01-merging/</guid>
      <description># Dependencies import pandas as pd raw_data_info = {  &amp;#34;customer_id&amp;#34;: [112, 403, 999, 543, 123],  &amp;#34;name&amp;#34;: [&amp;#34;John&amp;#34;, &amp;#34;Kelly&amp;#34;, &amp;#34;Sam&amp;#34;, &amp;#34;April&amp;#34;, &amp;#34;Bobbo&amp;#34;],  &amp;#34;email&amp;#34;: [&amp;#34;jman@gmail&amp;#34;, &amp;#34;kelly@aol.com&amp;#34;, &amp;#34;sports@school.edu&amp;#34;, &amp;#34;April@yahoo.com&amp;#34;, &amp;#34;HeyImBobbo@msn.com&amp;#34;] } info_df = pd.DataFrame(raw_data_info, columns=[&amp;#34;customer_id&amp;#34;, &amp;#34;name&amp;#34;, &amp;#34;email&amp;#34;]) info_df  # Create DataFrames raw_data_items = {  &amp;#34;customer_id&amp;#34;: [403, 112, 543, 999, 654],  &amp;#34;item&amp;#34;: [&amp;#34;soda&amp;#34;, &amp;#34;chips&amp;#34;, &amp;#34;TV&amp;#34;, &amp;#34;Laptop&amp;#34;, &amp;#34;Cooler&amp;#34;],  &amp;#34;cost&amp;#34;: [3.00, 4.50, 600, 900, 150] } items_df = pd.DataFrame(raw_data_items, columns=[  &amp;#34;customer_id&amp;#34;, &amp;#34;item&amp;#34;, &amp;#34;cost&amp;#34;]) items_df  # Merge two dataframes using an inner join merge_df = pd.</description>
    </item>
    
    <item>
      <title>01.  Terminal 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-01/01-terminal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/01-terminal/</guid>
      <description>cd Desktop will change to the desktop directory
mkdir PythonStuff will make a new directory/folder on the desktop.
cd PythonStuff will move to the newly created folder
open . on a Mac or
explorer . on a Windows will open the current folder
touch first_file.py will create a file
touch second_file.py will create a second file
ls will show what is in the current directory
cd .. will move us up a directory back to Desktop</description>
    </item>
    
    <item>
      <title>01.  Work Through Logistics  👩‍🎓👨‍🎓</title>
      <link>/21-neural-network-deep-learning/activities/day-01/01-work-through-logistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-01/01-work-through-logistics/</guid>
      <description>Work Through Logistics In this activity, you&amp;rsquo;ll use a logistic regression to categorize data from the make_blobs function from scikit-learn to create data.
Instructions   Use the starter code provided to create your make_blobs dataset from scikit-learn.
  Split your dataset into training and testing sets using scikit-learn&amp;rsquo;s train_test_split module.
  Create a LogisticRegression instance from scikit-learn&amp;rsquo;s LogisticRegression model.
  Hint   If you need a reminder on how to create a LogisticRegression model, review the Scikit-learn documentation.</description>
    </item>
    
    <item>
      <title>01. Automated Web Scrape 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-03/01-automated-web-scrape/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-03/01-automated-web-scrape/</guid>
      <description>Practice Performing an Automated Web Scrape In this activity, we&amp;rsquo;ll scrape data from a website that was created specifically for practicing our skills: Quotes to Scrape.
Instructions   First, open up Quotes to Scrape in Chrome and familiarize yourself with the page layout.
  Now let’s use DevTools to review the details of the “Top Ten tags” line. Right-click anywhere on the webpage, and then click Inspect. Note that in the DevTools panel, we can use a shortcut to choose an element on the page instead of searching through the tags.</description>
    </item>
    
    <item>
      <title>01. Basic Line Graphs 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-01/01-basic-line-graphs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/01-basic-line-graphs/</guid>
      <description>exponential chart  # Import Numpy for calculations and matplotlib for charting import numpy as np import matplotlib.pyplot as plt # Creates a numpy array from 0 to 5 with each step being 0.1 higher than the last x_axis = np.arange(0, 5, 0.1) x_axis  # Creates an exponential series of values which we can then chart e_x = [np.exp(x) for x in x_axis] e_x  # Create a graph based upon the list and array we have created plt.</description>
    </item>
    
    <item>
      <title>01. Basic Querying 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-02/01-basic-querying/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-02/01-basic-querying/</guid>
      <description>from sqlalchemy import create_engine from sqlalchemy import Column, Integer, String, Float  from sqlalchemy.ext.declarative import declarative_base Base = declarative_base() class BaseballPlayer(Base):  __tablename__ = &amp;#34;player&amp;#34;  player_id = Column(String, primary_key=True)  birth_year = Column(Integer)  birth_month = Column(Integer)  birth_day = Column(Integer)  birth_country = Column(String)  birth_state = Column(String)  birth_city = Column(String)  name_first = Column(String)  name_last = Column(String)  name_given = Column(String)  weight = Column(Integer)  height = Column(Integer)  bats = Column(String)  throws = Column(String)  debut = Column(String)  final_game = Column(String) # Create Database Connection engine = create_engine(&amp;#39;sqlite:///.</description>
    </item>
    
    <item>
      <title>01. Basic SQL Connection 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-01/01-basic-sql-connection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/01-basic-sql-connection/</guid>
      <description> # SQLAlchemy from sqlalchemy import create_engine  # Path to sqlite database_path = &amp;#34;./resources/Census_Data.sqlite&amp;#34;  # Create an engine that can talk to the database engine = create_engine(f&amp;#34;sqlite:///{database_path}&amp;#34;)  # Query All Records in the the Database data = engine.execute(&amp;#34;SELECT * FROM Census_Data&amp;#34;)  for record in data:  print(record) </description>
    </item>
    
    <item>
      <title>01. Cereal Cleaner 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-03/01-cereal-cleaner/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/01-cereal-cleaner/</guid>
      <description>In this activity, you will create an application that reads in cereal data from a CSV file and then prints only those cereals that contain 5 or more grams of fiber.
Instructions   Read the file using the code in the notebook, cereal.csv and start by skipping the header row. See hints below for this.
  Read through the remaining rows and find the cereals that contain five grams of fiber or more, printing the data from those rows to the terminal.</description>
    </item>
    
    <item>
      <title>01. CSS Identifier 👩‍🏫🧑‍🏫</title>
      <link>/11-data-collection/activities/day-02/01-css-identifier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-02/01-css-identifier/</guid>
      <description>from bs4 import BeautifulSoup html = &amp;#34;&amp;#34;&amp;#34; &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;en&amp;#34;&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt; &amp;lt;meta http-equiv=&amp;#34;X-UA-Compatible&amp;#34; content=&amp;#34;IE=edge&amp;#34;&amp;gt; &amp;lt;meta name=&amp;#34;viewport&amp;#34; content=&amp;#34;width=device-width, initial-scale=1.0&amp;#34;&amp;gt; &amp;lt;title&amp;gt;My First CSS Adventure&amp;lt;/title&amp;gt; &amp;lt;style&amp;gt; #cities { color: purple; } .meat { color: brown; } .vegetarian { color: green; } #favorite { color: orange; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;ol id=&amp;#34;cities&amp;#34;&amp;gt; &amp;lt;li&amp;gt;New York&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Paris&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Seoul&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Prague&amp;lt;/li&amp;gt; &amp;lt;/ol&amp;gt; &amp;lt;ol&amp;gt; &amp;lt;li class=&amp;#34;meat&amp;#34;&amp;gt;Taco&amp;lt;/li&amp;gt; &amp;lt;li class=&amp;#34;meat&amp;#34;&amp;gt;Burger&amp;lt;/li&amp;gt; &amp;lt;li class=&amp;#34;vegetarian&amp;#34;&amp;gt;Cheese pizza&amp;lt;/li&amp;gt; &amp;lt;li class=&amp;#34;vegetarian&amp;#34;&amp;gt;Mac and cheese&amp;lt;/li&amp;gt; &amp;lt;/ol&amp;gt; &amp;lt;ol&amp;gt; &amp;lt;li id=&amp;#34;favorite&amp;#34;&amp;gt;Star Wars&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Lion King&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Godfather&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Lord of the Rings&amp;lt;/li&amp;gt; &amp;lt;/ol&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; &amp;#34;&amp;#34;&amp;#34;  # Parse the code with Beautiful Soup soup = BeautifulSoup(html, &amp;#39;html.</description>
    </item>
    
    <item>
      <title>01. Data Normalization 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-03/01-data-normalization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/01-data-normalization/</guid>
      <description>Data Normalization First Form Normalization   Each field in a table row row should contain a single value.
  Each row is unique.
  Second Form Normalization   Be in first normal form.
  Single Column for Primary Key.
 Identifies the table uniquely    Third Form Normalization   Be in second normal form.
  Contain non-transitively dependent columns.
  </description>
    </item>
    
    <item>
      <title>01. Excel Playground 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/01-excel-playground/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/01-excel-playground/</guid>
      <description>Instructor Turn File:
 01-Ins_ExcelPlayground/Excel_Playground_Starter.xlsx  Note: The file includes a mock grade book.
 How to calculate the average grade for each student by using the average function in excel.
  how to copy a formula downstream in an Excel column. Either use copy and paste or drag the bottom-right corner of the cell, as in the following GIF:
  How you can pull up the Excel Formula Builder to access a GUI for Excel&amp;rsquo;s off-the-shelf formulas.</description>
    </item>
    
    <item>
      <title>01. Geoapify Geocode  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-03/01-geoapify-geocode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/01-geoapify-geocode/</guid>
      <description># Dependencies import requests import json  # Import the API key from config import geoapify_key # Target city target_city = &amp;#34;Sydney, Australia&amp;#34;  # Build the endpoint URL target_url = f&amp;#34;https://api.geoapify.com/v1/geocode/search?text={target_city}&amp;amp;format=json&amp;amp;apiKey={geoapify_key}&amp;#34; target_url &amp;#39;https://api.geoapify.com/v1/geocode/search?text=Sydney, Australia&amp;amp;format=json&amp;amp;apiKey=7757f89767bc454db74be2b640389f77&amp;#39; # Run a request to endpoint and convert result to json geo_data = requests.get(target_url).json()  # Print the json print(geo_data)  # Print the json (pretty printed) print(json.dumps(geo_data, indent=4, sort_keys=True))  # Extract latitude and longitude lat = geo_data[&amp;#34;results&amp;#34;][0][&amp;#34;lat&amp;#34;] lon = geo_data[&amp;#34;results&amp;#34;][0][&amp;#34;lon&amp;#34;]  # Print the latitude and longitude print(&amp;#39;&amp;#39;&amp;#39; City: {0}Latitude: {1}Longitude: {2}&amp;#39;&amp;#39;&amp;#39;.</description>
    </item>
    
    <item>
      <title>01. Github Playground 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-03/01-github/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/01-github/</guid>
      <description>Guide for Github steps:
  Visit https://github.com, and ask students to log in to their personal accounts.
  From the main page, create a new repository with an initializing README.md file, as detailed in the following screenshots and instructions. Explain that it’s standard in the tech world to include a &amp;ldquo;README&amp;rdquo; file that explains what each repository contains.
  Make the repository public so Graders can always access it for grading.</description>
    </item>
    
    <item>
      <title>01. Hello HTML 👩‍🏫🧑‍🏫</title>
      <link>/11-data-collection/activities/day-01/01-hello-html/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-01/01-hello-html/</guid>
      <description>&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;en-us&amp;#34;&amp;gt;  &amp;lt;head&amp;gt;  &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt;  &amp;lt;meta name=&amp;#34;viewport&amp;#34; content=&amp;#34;width=device-width, initial-scale=1.0&amp;#34;&amp;gt;  &amp;lt;title&amp;gt;My First Page&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt;  &amp;lt;body&amp;gt;   &amp;lt;!-- Header --&amp;gt;  &amp;lt;h1&amp;gt;Hello World!&amp;lt;/h1&amp;gt;   &amp;lt;!-- Image --&amp;gt;  &amp;lt;img src=&amp;#34;https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/11-Web/kids_dancing_hip_hop.png&amp;#34; alt=&amp;#34;children learning to dance hip-hop&amp;#34; /&amp;gt;  &amp;lt;br /&amp;gt;   &amp;lt;!-- Link with New Tab --&amp;gt;  &amp;lt;a href=&amp;#34;https://www.google.com&amp;#34; target=&amp;#34;_blank&amp;#34;&amp;gt;Opens new tab&amp;lt;/a&amp;gt;  &amp;lt;br /&amp;gt;   &amp;lt;!-- Bold Link --&amp;gt;  &amp;lt;strong&amp;gt;&amp;lt;a href=&amp;#34;https://www.</description>
    </item>
    
    <item>
      <title>01. Hello World👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-01/01-hello-world/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/01-hello-world/</guid>
      <description>Files: Activities/01-Ins_HelloWorld/Solved/hello_world.xlsm
  The first VBA script. Open the VBA editor, and navigate to Module 1. All examples in this lesson plan and the ones in the rest of the unit can be found in Module 1, as in the following images:
  The editor’s interface, and be sure to discuss the following points:
  Modules are organizational units of VBA code that are usually attached to a workbook or worksheet.</description>
    </item>
    
    <item>
      <title>01. Import Data 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-02/01-import-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/01-import-data/</guid>
      <description>Option 1 copy csv to sql table command COPY actor FROM &amp;#39;&amp;lt;path to actor.csv&amp;gt;&amp;#39; DELIMITER &amp;#39;,&amp;#39; CSV HEADER; COPY address FROM &amp;#39;&amp;lt;path to actor.csv&amp;gt;&amp;#39; DELIMITER &amp;#39;,&amp;#39; CSV HEADER; COPY city FROM &amp;#39;&amp;lt;path to city.csv&amp;gt;&amp;#39; DELIMITER &amp;#39;,&amp;#39; CSV HEADER; COPY country FROM &amp;#39;&amp;lt;path to country.csv&amp;gt;&amp;#39; DELIMITER &amp;#39;,&amp;#39; CSV HEADER; COPY customer_list FROM &amp;#39;&amp;lt;path to customer_list.csv&amp;gt;&amp;#39; DELIMITER &amp;#39;,&amp;#39; CSV HEADER; COPY customer FROM &amp;#39;&amp;lt;path to customer.csv&amp;gt;&amp;#39; DELIMITER &amp;#39;,&amp;#39; CSV HEADER; COPY film_actor FROM &amp;#39;&amp;lt;path to film_actor.</description>
    </item>
    
    <item>
      <title>01. JSON Traversal Review 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-02/01-json-traversal-review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/01-json-traversal-review/</guid>
      <description>JSON Traversal Review This activity is an opportunity to practice loading and parsing JSON in Python.
Instructions   Load the provided JSON.
  Retrieve the video&amp;rsquo;s title.
  Retrieve the video&amp;rsquo;s rating.
  Retrieve the link to the video&amp;rsquo;s first tag.
  Retrieve the number of views for the video.
  References Data Source: Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.</description>
    </item>
    
    <item>
      <title>01. Loc And Iloc 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-02/01-loc-and-iloc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/01-loc-and-iloc/</guid>
      <description>import pandas as pd file = &amp;#34;./resources/baton_streets.csv&amp;#34; original_df = pd.read_csv(file) original_df.head()  # Set new index to STREET NAME df = original_df.set_index(&amp;#34;STREET NAME&amp;#34;) df.head()  # Grab the data contained within the &amp;#34;ADDINGTON&amp;#34; row and the &amp;#34;STREET FULL NAME&amp;#34; column addington_name = df.loc[&amp;#34;ADDINGTON&amp;#34;, &amp;#34;STREET FULL NAME&amp;#34;] print(&amp;#34;Using Loc: &amp;#34; + addington_name)  also_addington_name = df.iloc[3, 1] print(&amp;#34;Using Iloc: &amp;#34; + also_addington_name)  # Grab the first five rows of data and the columns from &amp;#34;STREET NAME ID&amp;#34; to &amp;#34;POSTAL COMMUNITY&amp;#34; # The problem with using &amp;#34;STREET NAME&amp;#34; as the index is that the values are not unique so duplicates are returned # If there are duplicates and loc[] is being used, Pandas will return an error private_to_chalfont = df.</description>
    </item>
    
    <item>
      <title>01. Null Hypothesis 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-03/01-null-hypothesis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-03/01-null-hypothesis/</guid>
      <description>Forming a Null Hypothesis In this activity, you will turn two questions into a null hypothesis and an alternate hypothesis.
Instructions Form a hypothesis and null hypothesis for the following questions:
  Does dark chocolate affect arterial function in healthy individuals?
  Does coffee have anti-aging properties?
   Solutions Null Hypothesis   Does dark chocolate improve arterial function in healthy individuals?
  Alternate hypothesis - If dark chocolate is related to arterial function in healthy individuals, then consuming 30g of dark chocolate over a one-year period will result in improved arterial function.</description>
    </item>
    
    <item>
      <title>01. Plots Review  👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-02/01-plot-review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/01-plot-review/</guid>
      <description>PyPlot Warmup In this activity, you will use PyPlot to create the most effective visualization for a variety of datasets.
Instructions   Examine the starter code for each dataset.
  Determine what chart or plot fits with the starter code for each dataset.
  Complete the code block to create a plot for each of the datasets.
  Be sure to provide each plot with a title and labels.</description>
    </item>
    
    <item>
      <title>01. Push 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-02/01-pull/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-02/01-pull/</guid>
      <description></description>
    </item>
    
    <item>
      <title>01. Quick Check-Up 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-02/01-quick-check-up/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/01-quick-check-up/</guid>
      <description>Let’s start with a quick warm-up activity to get the Python juices flowing.
Instructions Create a simple Python program below that does the following:
  Prints &amp;ldquo;Hello User!&amp;rdquo;
  Then asks &amp;ldquo;What is your name?&amp;rdquo;
  Then responds &amp;ldquo;Hello &amp;lt;user&amp;rsquo;s name&amp;gt;&amp;rdquo;
  Then asks: &amp;ldquo;What is your favorite number? &amp;quot;
  Then responds: &amp;ldquo;Your favorite number is lower than mine.&amp;rdquo;, &amp;ldquo;Your favorite number is higher than mine.</description>
    </item>
    
    <item>
      <title>01. Request Intro  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-01/01-requests-intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/01-requests-intro/</guid>
      <description># Dependencies import requests import json   # URL for GET requests to retrieve vehicle data url = &amp;#34;https://api.spacexdata.com/v4/launchpads&amp;#34; # Print the response object to the console print(requests.get(url))  # Retrieving data and converting it into JSON print(requests.get(url).json())  # Pretty Print the output of the JSON response = requests.get(url).json() print(json.dumps(response, indent=4, sort_keys=True)) </description>
    </item>
    
    <item>
      <title>01. Star Counter 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-03/01-star-counter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-03/01-star-counter/</guid>
      <description>Star Counter The dataset you&amp;rsquo;ll be working with for this activity contains 50 rows of customer review data for French and Spanish online learning programs. Columns D through H contain the number of stars each program received as feedback. For example, the first row of the data indicates that a French program received two out of five stars in Monnie Mccasland&amp;rsquo;s review.
Data stored this way can be difficult to analyze, so you&amp;rsquo;ll be using VBA to convert it to numerical data.</description>
    </item>
    
    <item>
      <title>01. Summary Statistics 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-03/01-summary-statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/01-summary-statistics/</guid>
      <description># Dependencies import pandas as pd import matplotlib.pyplot as plt import scipy.stats as st import numpy as np # Read in the LAX temperature data temperature_df = pd.read_csv(&amp;#39;../Resources/lax_temperature.csv&amp;#39;) temperatures = temperature_df[&amp;#39;HourlyDryBulbTemperature&amp;#39;] # Demonstrate calculating measures of central tendency mean_numpy = np.mean(temperatures) print(f&amp;#34;The mean temperature at the LAX airport is {mean_numpy}&amp;#34;)  median_numpy = np.median(temperatures) print(f&amp;#34;The median temperature at the LAX airport is {median_numpy}&amp;#34;)  mode_scipy = st.mode(temperatures) print(f&amp;#34;The mode temperature at the LAX airport is {mode_scipy}&amp;#34;)  # Characterize the data set using matplotlib and stats.</description>
    </item>
    
    <item>
      <title>01. Warmup 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-02/01-warmup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-02/01-warmup/</guid>
      <description>Budget Checker In this activity, you&amp;rsquo;ll write a VBA script to run a budget checker in Excel.
Instructions   There are three parts to this problem.
  Part 1: Calculate the total amount after adding in the fee, and enter the value in the &amp;ldquo;Total&amp;rdquo; cell.
  Part 2: Create a message box to alert the user if the total amount, including the fee, is within or over budget.</description>
    </item>
    
    <item>
      <title>01. Workflows 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-01/01-workflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-01/01-workflow/</guid>
      <description>Workflow Diagrams Imagine that you&amp;rsquo;re working on a Git project.
 So far, you&amp;rsquo;ve made three different commits, all on your main branch. We&amp;rsquo;d write this as follows:  (main) | [m1] -&amp;gt; [m2] -&amp;gt; [m3]  [m1] is the first commit on the main branch; [m2] is the second, etc. The m comes from the fact that these commits are on the main branch.  Branching Whenever you want to either add something new or fix something broken, you should create a new branch for your work.</description>
    </item>
    
    <item>
      <title>01. Creating a Database 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-01/01-creating-a-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/01-creating-a-database/</guid>
      <description>Create a Database In this activity, everyone will create a database in pgAdmin from scratch.
Instructions To create a database in pgAdmin, follow these steps:
  In the pgAdmin editor, right-click the newly established server to create a new database.
  From the menu, select Create, and then select Database to create a new database.
  Enter animals_db as the database name. Make sure the owner is set as the default postgres, and then click Save.</description>
    </item>
    
    <item>
      <title>01. Pull 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-02/02-pull/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-02/02-pull/</guid>
      <description></description>
    </item>
    
    <item>
      <title>02. </title>
      <link>/10-advanced-sql/activities/day-03/02/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/02/</guid>
      <description></description>
    </item>
    
    <item>
      <title>02.  Census Merging 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-03/02-census-merging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-03/02-census-merging/</guid>
      <description>Census Merging In this activity, you will merge the two Census datasets that we created in the last class and then do a calculation and sort the values.
Instructions   Read in both of the CSV files, and print out their DataFrames.
  Perform an inner merge that combines both DataFrames on the &amp;ldquo;Year&amp;rdquo; and &amp;ldquo;State&amp;rdquo; columns.
  Create a DataFrame that filters the data on only 2019.</description>
    </item>
    
    <item>
      <title>02.  Comic Remix 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-01/02-comics-remix/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/02-comics-remix/</guid>
      <description>For this activity, you will be creating a Jupyter notebook that performs the same functions as the Comic Book activity from last week.
Instructions   Using comicbooks.py as a starting point, convert the application so that it runs properly within a Jupyter Notebook.
  Have the application print out the user&amp;rsquo;s input, the path to comic_books.csv, and the publisher/date published for the book in different cells.
  Bonus  Go through any of the activities from last week, and attempt to convert them to run within a Jupyter Notebook.</description>
    </item>
    
    <item>
      <title>02.  Good Movies Loc 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-02/02-good-movies-loc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/02-good-movies-loc/</guid>
      <description>Good Movies In this activity, you will create an application that searches through IMDb data to find only the best movies out there.
Instructions   Use Pandas to load and display the CSV provided in resources.
  List all the columns in the dataset.
  We&amp;rsquo;re only interested in IMDb data, so create a new table that takes the film and all the columns related to IMDb.</description>
    </item>
    
    <item>
      <title>02.  Work through Neural Network 👩‍🏫🧑‍🏫</title>
      <link>/21-neural-network-deep-learning/activities/day-01/02-work-through-nn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-01/02-work-through-nn/</guid>
      <description>%matplotlib # Import our dependencies import pandas as pd import matplotlib as plt from sklearn.datasets import make_blobs import sklearn as skl import tensorflow as tf Using matplotlib backend: MacOSX # Generate dummy dataset X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=78)  # Creating a DataFrame with the dummy data df = pd.DataFrame(X, columns=[&amp;#34;Feature 1&amp;#34;, &amp;#34;Feature 2&amp;#34;]) df[&amp;#34;Target&amp;#34;] = y  # Plotting the dummy data df.plot.scatter(x=&amp;#34;Feature 1&amp;#34;, y=&amp;#34;Feature 2&amp;#34;, c=&amp;#34;Target&amp;#34;, colormap=&amp;#34;winter&amp;#34;)   # Use sklearn to split dataset from sklearn.</description>
    </item>
    
    <item>
      <title>02. 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-01/02-spacex-request/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/02-spacex-request/</guid>
      <description>Requesting SpaceX In this activity, you will dig into a simple, well-documented API—The SpaceX API—and make calls to the API using the Requests library.
Instructions   Take a few minutes to explore the SpaceX V3 API:
  GitHub
  API Documentation
    Once you understand the structure of the API and its endpoint, choose one of the endpoints and do the following:
  Retrieve and print the JSON for all of the records from your chosen endpoint.</description>
    </item>
    
    <item>
      <title>02. Aggregates 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-02/02-aggregates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/02-aggregates/</guid>
      <description>-- Select everything from film table SELECT * FROM film;  -- Count the amount of film_id&amp;#39;s in film table SELECT COUNT(film_id) FROM film;  -- Create an alias SELECT COUNT(film_id) AS &amp;#34;Total films&amp;#34; FROM film;  -- Group by rating and aggregate the film_id count SELECT rating, COUNT(film_id) AS &amp;#34;Total films&amp;#34; FROM film GROUP BY rating;  -- Select the average rental duration SELECT AVG(rental_duration) FROM film;  -- Create an Alias SELECT AVG(rental_duration) AS &amp;#34;Average rental period&amp;#34; FROM film;  -- Group by the rental duration, average the rental rate and give alias SELECT rental_duration, AVG(rental_rate) AS &amp;#34;Average rental rate&amp;#34; FROM film GROUP BY rental_duration;  -- Find the rows with the minimum rental rate SELECT rental_duration, MIN(rental_rate) AS &amp;#34;Min rental rate&amp;#34; FROM film GROUP BY rental_duration;  -- Find the rows with the maximum rental rate SELECT rental_duration, MAX(rental_rate) AS &amp;#34;Max rental rate&amp;#34; FROM film GROUP BY rental_duration; </description>
    </item>
    
    <item>
      <title>02. Basic Charting  👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-03/02-basic-charting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/02-basic-charting/</guid>
      <description>PC Excel chart options are captured in the following image:
  Mac Excel chart options are captured in the following image:
  Excel enables users to create many kinds of charts, but first we’ll create a bar chart since that fits our data nicely.
  Whenever you select a charting option from the “Charts” group, a new menu will appear that allows you to select various visual options.</description>
    </item>
    
    <item>
      <title>02. Case Study 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-02/02-case-study/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-02/02-case-study/</guid>
      <description>CSS Case Study In this activity, you’ll use CSS selectors in a basic web scraping example. First, you’ll use the class selector. Then, you’ll use the id selector.
Instructions   Import BeautifulSoup.
  Save the provided HTML code as a Python string.
  Convert the HTML string into a BeautifulSoup object.
  Use the find_all function to retrieve all of the elements that belong to the odd class.</description>
    </item>
    
    <item>
      <title>02. Data Normalization 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-03/02-data-normalization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/02-data-normalization/</guid>
      <description>In this activity, you will use data normalization practices.
Instructions   In pgAdmin, create a new database called pets_db.
  Use Excel to get the data into first normal form (1NF).
  Using the normalized CSV, create the following tables with continued normalized practices:
A table for owners that takes an ID and the owner&amp;rsquo;s name.
A table for pet names that takes two IDs, the pet&amp;rsquo;s name, and the pet&amp;rsquo;s type.</description>
    </item>
    
    <item>
      <title>02. Dictionary 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-03/02-dictionary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/02-dictionary/</guid>
      <description># Unlike lists, dictionaries store information in pairs # ---------------------------------------------------------------  # Create a dictionary to hold the actor&amp;#39;s names. actors = {}  # Create a dictionary using the built-in function. actors = dict()  # A dictionary of an actor. actors = {&amp;#34;name&amp;#34;: &amp;#34;Tom Cruise&amp;#34;} print(f&amp;#39;{actors[&amp;#34;name&amp;#34;]}&amp;#39;)  # Add an actor to the dictionary with the key &amp;#34;name&amp;#34; # and the value &amp;#34;Denzel Washington&amp;#34;. actors[&amp;#34;name&amp;#34;] = &amp;#34;Denzel Washington&amp;#34;  # Print the actors dictionary.</description>
    </item>
    
    <item>
      <title>02. first HTML 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-01/02-first-html/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-01/02-first-html/</guid>
      <description>In this activity, you will create a simple HTML page.
Instructions In a new HTML file, create the basic structure of an HTML document and include in it the following:
  DOCTYPE declaration
  &amp;lt;head&amp;gt; element with nested &amp;lt;title&amp;gt; element
  &amp;lt;h1&amp;gt; element with a title of your choice
  An image
  A link to an external page, such as google.com
  An ordered list of things to do on your next vacation</description>
    </item>
    
    <item>
      <title>02. For Loop 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-02/02-forloops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-02/02-forloops/</guid>
      <description>Sub forLoop()   &amp;#39; Create a variable to hold the counter  Dim i As Integer   &amp;#39; Loop through from numbers 1 through 20  For i = 1 To 20   &amp;#39; Iterate through the rows placing a value of 1 throughout  Cells(i, 1).Value = 1   &amp;#39; Iterate through the columns placing a value of 5 throughout  Cells(1, i).Value = 5   &amp;#39; Places increasing values based upon the variable &amp;#34;i&amp;#34; in B2 to B21  Cells(i + 1, 2).</description>
    </item>
    
    <item>
      <title>02. Formatter 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-03/02-formatter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-03/02-formatter/</guid>
      <description>Sub formatter()   &amp;#39; Set the Font color to Red  Range(&amp;#34;A1&amp;#34;).Font.ColorIndex = 3   &amp;#39; Set the Cell Colors to Red  Range(&amp;#34;A2:A5&amp;#34;).Interior.ColorIndex = 3   &amp;#39; Set the Font Color to Green  Range(&amp;#34;B1&amp;#34;).Font.ColorIndex = 4   &amp;#39; Set the Cell Colors to Green  Range(&amp;#34;B2:B5&amp;#34;).Interior.ColorIndex = 4   &amp;#39; Set the Color Index to Blue  Range(&amp;#34;C1&amp;#34;).Font.ColorIndex = 5   &amp;#39; Set the Cell Colors to Blue  Range(&amp;#34;C2:C5&amp;#34;).</description>
    </item>
    
    <item>
      <title>02. Geoapify Places  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-03/02-geoapify-places/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/02-geoapify-places/</guid>
      <description>Geoapify Places Demo # Dependencies import requests import json  # Import the API key from config import geoapify_key # Set the geographical coordinates for Sydney, Australia latitude = -33.8698439 longitude = 151.2082848  # Set the parameters for the type of place categories = &amp;#34;catering.restaurant&amp;#34; conditions = &amp;#34;vegetarian&amp;#34; radius = 8000  # Set the parameters for the type of search filters = f&amp;#34;circle:{longitude},{latitude},{radius}&amp;#34; bias = f&amp;#34;proximity:{longitude},{latitude}&amp;#34; limit = 20  # set up a parameters dictionary params = {  &amp;#34;categories&amp;#34;:categories,  &amp;#34;conditions&amp;#34;:conditions,  &amp;#34;limit&amp;#34;:limit,  &amp;#34;filter&amp;#34;:filters,  &amp;#34;bias&amp;#34;:bias,  &amp;#34;apiKey&amp;#34;:geoapify_key }  # Set base URL base_url = &amp;#34;https://api.</description>
    </item>
    
    <item>
      <title>02. Hello VBA 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-01/02-hello-vba/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/02-hello-vba/</guid>
      <description>Hello, VBA It’s time to write your first VBA script!
Instructions   Create and execute a VBA script that generates three pop-up messages containing any text of your choice.
  If you finish early, try to help other students complete the activity.
  —
✅ Solutions   Solutions Click Here   Sub HelloVBA():   MsgBox (&amp;#34;Hello VBA!&amp;#34;)  MsgBox (&amp;#34;I have come to master your vicissitudes.</description>
    </item>
    
    <item>
      <title>02. Ice Cream Connection 👩‍🎓👨‍🎓</title>
      <link>/10-advanced-sql/activities/day-01/02-ice-cream-connection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/02-ice-cream-connection/</guid>
      <description>Ice Cream Connection In this activity, you will create, connect to, and insert data into a new database by using SQLAlchemy.
Instructions   Use the database path to create a SQLite engine.
  Use the engine to select all of the rows and columns from the table icecreamstore.
  Create a new query that finds the ice cream flavors that cost more than 2.0.
   Reference Mockaroo, LLC.</description>
    </item>
    
    <item>
      <title>02. Named Ranges 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/02-named-ranges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/02-named-ranges/</guid>
      <description>Instructor Turn  02-Ins_NamedRanges/ShoppingTrip.xlsx   Open the exercise, and begin to highlight entire columns of existing data (e.g., A1:A6, B1:B6, etc.).  Note: The upper-left corner, before the Formula Bar, has a Name Box.
This shows the currently selected cell, or if a named range is selected, the name of the named range. These names can be created by selecting any set of cells and clicking the Name Box to insert a name, as in the following image:</description>
    </item>
    
    <item>
      <title>02. NJ Templ Line Plots 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-01/02-nj-temp-line-plots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/02-nj-temp-line-plots/</guid>
      <description>New Jersey Weather In this activity, you will visualize the differences between temperature recorded in degrees Fahrenheit versus degrees Celsius.
Instructions   Using the following data, plot the monthly averages for temperature in New Jersey in both degrees Fahrenheit and degrees Celsius.
 Average temperature per month in Fahrenheit: 39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44.    Assign to the x-axis a range of numerical values representing each month of the year.</description>
    </item>
    
    <item>
      <title>02. Pandas plot 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-02/02-pandas-plot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/02-pandas-plot/</guid>
      <description>%matplotlib notebook # Dependencies import matplotlib.pyplot as plt import numpy as np import pandas as pd  ## Using MatplotLib to Chart a DataFrame # Load in csv rain_df = pd.read_csv(&amp;#34;../Resources/avg_rain_state.csv&amp;#34;) rain_df.head()  # Set x axis and tick locations x_axis = np.arange(len(rain_df)) tick_locations = [value for value in x_axis]  # Create a list indicating where to write x labels and set figure size to adjust for space plt.</description>
    </item>
    
    <item>
      <title>02. Quartiles and Outliers 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-03/02-quartiles-and-outliers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/02-quartiles-and-outliers/</guid>
      <description># Dependencies import pandas as pd import numpy as np import matplotlib.pyplot as plt # Example outlier plot of reaction times times = [96,98,100,105,85,88,95,100,101,102,97,98,5] fig1, ax1 = plt.subplots() ax1.set_title(&amp;#39;Reaction Times at Baseball Batting Cage&amp;#39;) ax1.set_ylabel(&amp;#39;Reaction Time (ms)&amp;#39;) ax1.boxplot(times) plt.show()  # We need to sort the data to determine which could be outliers times.sort() print(times)  # The second example again looks at the LAX temperature data set and computes quantiles temperature_df = pd.</description>
    </item>
    
    <item>
      <title>02. Request Review👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-02/02-request-review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/02-request-review/</guid>
      <description>Requests &amp;amp; Responses This activity provides practice making requests, converting the response to JSON, and then manipulating the result with Python.
Instructions   Make a request to the following endpoint (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/06-Python-APIs/request_review.json), and store the response.
  Print the JSON representations of the first and last posts.
  Print number of posts received.
  References Data Source: Mockaroo, LLC. (2021). Realistic Data Generator. https://www.mockaroo.com/
 ✅ Solutions   Solutions Click Here    # Dependencies import json import requests from pprint import pprint # Specify the URL url = &amp;#34;https://2u-data-curriculum-team.</description>
    </item>
    
    <item>
      <title>02. Scrape Multiple Pages 👩‍🏫🧑‍🏫</title>
      <link>/11-data-collection/activities/day-03/02-scrape-multiple-pages/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-03/02-scrape-multiple-pages/</guid>
      <description></description>
    </item>
    
    <item>
      <title>02. Simple Loops 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-02/02-simple-loops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/02-simple-loops/</guid>
      <description># A For loop moves through a given range of numbers # If only one number is provided it will loop from 0 to that number for x in range(10):  print(x)  # If two numbers are provided then a For loop will loop from the first number up until it reaches the second number for x in range(20, 30):  print(x)  # If a list is provided, then the For loop will loop through each element within the list words = [&amp;#34;Peanut&amp;#34;, &amp;#34;Butter&amp;#34;, &amp;#34;Jelly&amp;#34;, &amp;#34;Time&amp;#34;, &amp;#34;Is&amp;#34;, &amp;#34;Now&amp;#34;] for word in words:  print(word)  # A While Loop will continue to loop through the code contained within it until some condition is met x = &amp;#34;Yes&amp;#34; while x == &amp;#34;Yes&amp;#34;:  print(&amp;#34;Whee!</description>
    </item>
    
    <item>
      <title>02. Sunny Hours  👩‍🎓👨‍🎓</title>
      <link>/10-advanced-sql/activities/day-02/02-sunny/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-02/02-sunny/</guid>
      <description>Sunny Hours For this activity, you will create a Python script that can search through the provided SQL file of hours of sunshine in various cities in the world.
Instructions   Use sunshine.sqlite as your data source.
  Within a Python script, create a Sunshine class to read in all of the columns of the database. Consult the SQL schema of the sunshine table when creating your class. Note that the REAL data type refers to floating point numbers (decimals).</description>
    </item>
    
    <item>
      <title>02. Terminal 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-01/02-terminal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/02-terminal/</guid>
      <description>Terminal Now, it&amp;rsquo;s your turn to do some work in the terminal. You&amp;rsquo;ll create three folders and a pair of Python files to print strings of your own creation to the console.
Instructions Use the following instructions to write commands in your terminal:
  Create a folder called LearnPython.
  Navigate into the folder.
  Inside LearnPython, create another folder called Assignment1.
  Inside Assignment1, create a file called quick_python.</description>
    </item>
    
    <item>
      <title>02. TTest 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-03/02-ttest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-03/02-ttest/</guid>
      <description>import warnings warnings.filterwarnings(&amp;#39;ignore&amp;#39;) %matplotlib inline from matplotlib import pyplot as plt import numpy as np import scipy.stats as stats  # Helper Functions to Generate and Plot Data # Generate some fake data to test with def gendata(loc=0):  population = stats.norm.rvs(size=1000, random_state=42)  sample = stats.norm.rvs(loc=loc, size=200, random_state=42)   # Scatter Plot of Data  plt.subplot(2, 1, 1)  plt.scatter(range(len(population)), population, label=&amp;#34;population&amp;#34;)  plt.scatter(range(len(sample)), sample, label=&amp;#34;sample&amp;#34;)  plt.</description>
    </item>
    
    <item>
      <title>02. Workflow 👩‍🎓👨‍🎓</title>
      <link>/07-project-1-part-1/activities/day-01/02-workflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-01/02-workflow/</guid>
      <description>Review Questions This document contains review questions about Git basics.
Instructions For the following diagramming exercises, either draw your solutions on paper or use the interface provided at Git Viz.
Overview   Consider the example from the lecture, where we created a branch for our data analysis. Why did we create a new branch for this? Why not simply do this on main?
  Write down two advantages to creating branches instead of working directly on main.</description>
    </item>
    
    <item>
      <title>02. Creating a Table 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-01/02-creating-tables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/02-creating-tables/</guid>
      <description>-- Create a new table CREATE TABLE people (  name VARCHAR(30) NOT NULL,  has_pet BOOLEAN DEFAULT false,  pet_type VARCHAR(10) NOT NULL,  pet_name VARCHAR(30),  pet_age INT );  -- Query all fields from the table SELECT * FROM people;  -- Insert data into the table INSERT INTO people (name, has_pet, pet_type, pet_name, pet_age) VALUES (&amp;#39;Jacob&amp;#39;, true, &amp;#39;dog&amp;#39;, &amp;#39;Misty&amp;#39;, 10),  (&amp;#39;Ahmed&amp;#39;, true, &amp;#39;rock&amp;#39;, &amp;#39;Rockington&amp;#39;, 100),  (&amp;#39;Peter&amp;#39;, true, &amp;#39;cat&amp;#39;, &amp;#39;Franklin&amp;#39;, 2),  (&amp;#39;Dave&amp;#39;, true, &amp;#39;dog&amp;#39;, &amp;#39;Queso&amp;#39;, 1);  -- Query only the `pet_name` field SELECT pet_name FROM people;  -- Filter the query to show only dogs under the age of 5 SELECT pet_type, pet_name FROM people WHERE pet_type = &amp;#39;dog&amp;#39; AND pet_age &amp;lt; 5; </description>
    </item>
    
    <item>
      <title>03. </title>
      <link>/10-advanced-sql/activities/day-03/03/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/03/</guid>
      <description></description>
    </item>
    
    <item>
      <title>03.  BYONNM 👩‍🎓👨‍🎓</title>
      <link>/21-neural-network-deep-learning/activities/day-01/03-byonnm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-01/03-byonnm/</guid>
      <description>Bring Your Own Neural Network Model In this activity, you&amp;rsquo;ll use a neural network model to classify the data from make_blobs.
Instructions   Using the starter code provided, visualize the blobs dummy dataset using a Pandas scatter plot.
  Randomly split the dummy data into training and test datasets using scikit-learn&amp;rsquo;s train_test_split method.
  Normalize both datasets using scikit-learn&amp;rsquo;s StandardScaler class.
  Using the Keras module, create a basic neural network with five neurons in the hidden layer.</description>
    </item>
    
    <item>
      <title>03.  Census Merging 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-03/03-binning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-03/03-binning/</guid>
      <description># Import Dependencies import pandas as pd raw_data = {  &amp;#39;Class&amp;#39;: [&amp;#39;Oct&amp;#39;, &amp;#39;Oct&amp;#39;, &amp;#39;Jan&amp;#39;, &amp;#39;Jan&amp;#39;, &amp;#39;Oct&amp;#39;, &amp;#39;Jan&amp;#39;],  &amp;#39;Name&amp;#39;: [&amp;#34;Cyndy&amp;#34;, &amp;#34;Logan&amp;#34;, &amp;#34;Laci&amp;#34;, &amp;#34;Elmer&amp;#34;, &amp;#34;Crystle&amp;#34;, &amp;#34;Emmie&amp;#34;],  &amp;#39;Test Score&amp;#39;: [90, 59, 72, 88, 98, 60]} df = pd.DataFrame(raw_data) df  # Create the bins in which Data will be held # Bins are 0, 59.9, 69.9, 79.9, 89.9, 100.  bins = [0, 59.9, 69.9, 79.9, 89.9, 100]  # Create the names for the five bins group_names = [&amp;#34;F&amp;#34;, &amp;#34;D&amp;#34;, &amp;#34;C&amp;#34;, &amp;#34;B&amp;#34;, &amp;#34;A&amp;#34;] df[&amp;#34;Test Score Summary&amp;#34;] = pd.</description>
    </item>
    
    <item>
      <title>03.  Cleaning Data 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-02/03-cleaning-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/03-cleaning-data/</guid>
      <description># Dependencies import pandas as pd # Name of the CSV file file = &amp;#39;resources/donors2021_unclean.csv&amp;#39; # The correct encoding must be used to read the CSV in pandas df = pd.read_csv(file, encoding=&amp;#34;ISO-8859-1&amp;#34;) # Preview of the DataFrame # Note that Memo_CD is likely a meaningless column df.head()  # Delete extraneous column del df[&amp;#39;Memo_CD&amp;#39;] df.head()  # Identify incomplete rows df.count()  # Drop all rows with missing information df = df.</description>
    </item>
    
    <item>
      <title>03.  Geoapify Drills👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-03/03-geoapify-drills/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/03-geoapify-drills/</guid>
      <description>Geoapify Drills In this activity, you will perform API calls to the Geoapify places and geocoding endpoints.
Instructions  Complete each of the six drills articulated in the code provided in geoapify_drills.ipynb. Feel encouraged to look back at the previous examples, but know that you will have to consult the Geoapify API documentation.  Hints   See the Geoapify Geocoding Documentation.
  See the Geoapify Places Documentation.
   </description>
    </item>
    
    <item>
      <title>03.  Gregarious Aggregates 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-02/03-gregarious-aggregates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/03-gregarious-aggregates/</guid>
      <description>✅ Solutions   Solutions Click Here   -- 1. What is the average cost to rent a film in the pagila stores? SELECT AVG(rental_rate) AS &amp;#34;Average rental rate&amp;#34; FROM film;  -- 2. What is the average rental cost of films by rating? On average, what is the cheapest rating of films to rent? Most expensive? SELECT rating, AVG(rental_rate) AS &amp;#34;Average rental rate&amp;#34; FROM film GROUP BY rating;  -- 3.</description>
    </item>
    
    <item>
      <title>03.  Kid in a Candy Store  👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-02/03-candy-store/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/03-candy-store/</guid>
      <description>In this activity, you will create the code that a candy store will use in their state-of-the-art candy vending machine.
Instructions   Create a loop that prints all of the candies in the store to the terminal, with their index stored in brackets beside them.
 For example: &amp;quot;[0] Snickers&amp;quot;    Create a second loop that runs for a set number of times determined by the variable allowance.</description>
    </item>
    
    <item>
      <title>03.  Variables 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-01/03-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/03-variables/</guid>
      <description># Creates a variable with a string &amp;#34;Frankfurter&amp;#34; title = &amp;#34;Frankfurter&amp;#34;  # Creates a variable with an integer 80 years = 80  # Creates a variable with the boolean value of True expert_status = True  # Prints a statement adding the variable print(&amp;#34;Nick is a professional &amp;#34; + title)  # Convert the integer years into a string and prints print(&amp;#34;He has been coding for &amp;#34; + str(years) + &amp;#34; years&amp;#34;)  # Converts a boolean into a string and prints print(&amp;#34;Expert status: &amp;#34; + str(expert_status))  # An f-string accepts all data types without conversion print(f&amp;#34;Expert status: {expert_status}&amp;#34;) </description>
    </item>
    
    <item>
      <title>03. Basic Updating 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-02/03-basic-updating/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-02/03-basic-updating/</guid>
      <description>from sqlalchemy import create_engine, Column, Integer, String from sqlalchemy.ext.declarative import declarative_base Base = declarative_base()  # Define our pet table class Pet(Base):  __tablename__ = &amp;#39;pet&amp;#39;  id = Column(Integer, primary_key=True)  name = Column(String)  type = Column(String)  age = Column(Integer) # Right now, this table only exists in python and not in the actual database Base.metadata.tables  # Create our database engine engine = create_engine(&amp;#39;sqlite:///pets.sqlite&amp;#39;) # This is where we create our tables in the database Base.</description>
    </item>
    
    <item>
      <title>03. BeautifulSoup</title>
      <link>/11-data-collection/activities/day-01/03-beautifulsoup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-01/03-beautifulsoup/</guid>
      <description># Introduction to BeautifulSoup # Import BeautifulSoup  from bs4 import BeautifulSoup   # Store html site as a string html = &amp;#34;&amp;#34;&amp;#34; &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;en-us&amp;#34;&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt; &amp;lt;title&amp;gt;My First Page&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;!-- Header --&amp;gt; &amp;lt;h1&amp;gt;Hello World!&amp;lt;/h1&amp;gt; &amp;lt;!-- Image --&amp;gt; &amp;lt;img src=&amp;#34;https://static.wikia.nocookie.net/spongebob/images/4/46/SVG_SpongeBob_SquarePants.svg/revision/latest/scale-to-width-down/195?cb=20181117230211&amp;#34; alt=&amp;#34;Spongebob!&amp;#34; /&amp;gt; &amp;lt;br /&amp;gt; &amp;lt;!-- Link with New Tab --&amp;gt; &amp;lt;a href=&amp;#34;https://www.google.com&amp;#34;&amp;gt;Google&amp;lt;/a&amp;gt; &amp;lt;br /&amp;gt; &amp;lt;!-- An ordered list --&amp;gt; &amp;lt;ol&amp;gt; &amp;lt;li&amp;gt;Visit Grand Canyon&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Hike the trails&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Take photos&amp;lt;/li&amp;gt; &amp;lt;/ol&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;Bach&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Mozart&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Beethoven&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Adele&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; &amp;#34;&amp;#34;&amp;#34;  # Create a BeautifulSoup object to parse the html code soup = BeautifulSoup(html, &amp;#39;html.</description>
    </item>
    
    <item>
      <title>03. Branch 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-01/03-branch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-01/03-branch/</guid>
      <description>Branch Demo 0. Getting the Repo Before we can work with Git, we must either create a new repository, or clone one from GitHub.
Note that, in the examples below, we use git status before every git commit. This is a best practice that helps ensure a deliberate commit history. For brevity&amp;rsquo;s sake, this line will be omitted in future files, but assume we&amp;rsquo;ve always run git status before any git commit.</description>
    </item>
    
    <item>
      <title>03. Button Clicks 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-01/03-button-clicks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/03-button-clicks/</guid>
      <description>Files: 03-Ins_ButtonClicks
  Next, return to the Developer tab, where you’ll insert a button in their spreadsheet. The Mac layout is slightly different, so be patient if you have any difficulty finding features across operating systems.
  First, create a button, as in the following image:   Once the button is created, the &amp;ldquo;Assign Macro&amp;rdquo; window will pop up, where you can choose to create a new macro or select an existing one, as in the following image:   If you accidentally close this window, you can always re-open it by right-clicking your button and selecting &amp;ldquo;Assign Macro&amp;rdquo;</description>
    </item>
    
    <item>
      <title>03. Chicken Nuggets 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-02/03-chicken-nuggets-for-loop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-02/03-chicken-nuggets-for-loop/</guid>
      <description>Looping on Through Now, it&amp;rsquo;s your chance to see how quickly we can create data using the power of a computer and for loops!
Instructions Create a for loop that will produce the following example. The lines signify new cells.
   A B C     I will eat 11 Chicken Nuggets   I will eat 12 Chicken Nuggets   I will eat 13 Chicken Nuggets   I will eat 14 Chicken Nuggets   I will eat 15 Chicken Nuggets   I will eat 16 Chicken Nuggets   I will eat 17 Chicken Nuggets   I will eat 18 Chicken Nuggets   I will eat 19 Chicken Nuggets   I will eat 20 Chicken Nuggets    Bonus If you finish early, consider why you may prefer using a for loop over the range() function.</description>
    </item>
    
    <item>
      <title>03. Color Counter 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/03-color-counter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/03-color-counter/</guid>
      <description>Instructor Turn File:
 03-Ins_ColorCounter/FavoriteColors.xlsx.  In this example, a column of colors is listed.
  A row of color counters uses conditional statements like COUNTIF(Colors,&amp;ldquo;Red&amp;rdquo;) to count the instances of each color.
  A second row of &amp;ldquo;Above Five&amp;rdquo; counters use a different conditional statement (IF(C2&amp;gt;5), &amp;quot;TRUE&amp;quot;, &amp;quot;FALSE&amp;quot;) to check if the color count exceeds five for each color.
  Note: That in both cases, the cell value is determined by the respective conditional formula, as in the following image:</description>
    </item>
    
    <item>
      <title>03. Configuring Line Plots 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-01/03-configuring-line-plots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/03-configuring-line-plots/</guid>
      <description>%matplotlib notebook # Dependencies import matplotlib.pyplot as plt import numpy as np # Set x axis and variables x_axis = np.arange(0, 10, 0.1) sin = np.sin(x_axis) cos = np.cos(x_axis) # Draw a horizontal line with 0.25 transparency plt.hlines(0, 0, 10, alpha=0.25)   # Assign plots to tuples that stores result of plot  # Each point on the sine chart is marked by a blue circle sine_handle, = plt.</description>
    </item>
    
    <item>
      <title>03. Dictionary  👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-03/03-dictionary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/03-dictionary/</guid>
      <description>In this activity, you will create and access dictionaries that are based on your own hobbies.
Instructions  Create a dictionary to store the following information:   Your name Your age A list of a few of your hobbies A dictionary that includes a few days and the time you typically wake up on those days  Print out your name, how many hobbies you have, and a time you typically wake up during the week.</description>
    </item>
    
    <item>
      <title>03. Foreign Keys 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-03/03-foreign-keys/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/03-foreign-keys/</guid>
      <description>CREATE TABLE animals_all (  id SERIAL PRIMARY KEY,  animal_species VARCHAR(30) NOT NULL,  owner_name VARCHAR(30) NOT NULL );  INSERT INTO animals_all (animal_species, owner_name) VALUES  (&amp;#39;Dog&amp;#39;, &amp;#39;Bob&amp;#39;),  (&amp;#39;Fish&amp;#39;, &amp;#39;Bob&amp;#39;),  (&amp;#39;Cat&amp;#39;, &amp;#39;Kelly&amp;#39;),  (&amp;#39;Dolphin&amp;#39;, &amp;#39;Aquaman&amp;#39;);  SELECT * FROM animals_all;  CREATE TABLE animals_location (  id SERIAL PRIMARY KEY,  location VARCHAR(30) NOT NULL,  animal_id INTEGER NOT NULL,  FOREIGN KEY (animal_id) REFERENCES animals_all(id) );  -- Insert data INSERT INTO animals_location (location, animal_id) VALUES  (&amp;#39;Dog House&amp;#39;, 1),  (&amp;#39;Fish Tank&amp;#39;, 2),  (&amp;#39;Bed&amp;#39;, 3),  (&amp;#39;Ocean&amp;#39;, 4);  SELECT * FROM animals_location;  -- Insert error INSERT INTO animals_location (location, animal_id) VALUES (&amp;#39;River&amp;#39;, 5);  -- Correct insert INSERT INTO animals_all (animal_species, owner_name) VALUES  (&amp;#39;Fish&amp;#39;, &amp;#39;Dave&amp;#39;);  INSERT INTO animals_location (location, animal_id) VALUES  (&amp;#39;River&amp;#39;, 5);  SELECT * FROM animals_location; </description>
    </item>
    
    <item>
      <title>03. Gradebook 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-03/03-vba-gradebook/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-03/03-vba-gradebook/</guid>
      <description>VBA Grade Book In this activity, you will create a macro that will check a student’s numerical grade, assign them a letter grade, and apply different formatting changes to a cell depending on the value of the student’s grade.
Instructions With grader.xlsm as your starting point, create a grade calculator using conditionals. This calculator will convert a student&amp;rsquo;s numeric grade into a letter grade and then style the resulting cell accordingly.</description>
    </item>
    
    <item>
      <title>03. Group Plots 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-02/04-group-plots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/04-group-plots/</guid>
      <description>%matplotlib notebook  # Import Dependencies import matplotlib.pyplot as plt import pandas as pd # Import our data into pandas from CSV accident_string = &amp;#39;../Resources/accidents.csv&amp;#39; accidents_df = pd.read_csv(accident_string, low_memory=False)  accidents_df  # Create a group based on the values in the &amp;#39;FUNC_SYSNAME&amp;#39; column # &amp;#39;FUNC_SYSNAME&amp;#39; stores the type of road the accident occurred accident_road_type = accidents_df.groupby(&amp;#39;FUNC_SYSNAME&amp;#39;)  # Count how many times each road type appears in our group count_road_types = accident_road_type[&amp;#39;FUNC_SYSNAME&amp;#39;].</description>
    </item>
    
    <item>
      <title>03. Intro to pandas 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-01/03-intro-to-pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/03-intro-to-pandas/</guid>
      <description># Dependencies import pandas as pd # We can create a Pandas Series from a raw list data_series = pd.Series([&amp;#34;UCLA&amp;#34;, &amp;#34;UC Berkeley&amp;#34;, &amp;#34;UC Irvine&amp;#34;,  &amp;#34;University of Central Florida&amp;#34;, &amp;#34;Rutgers University&amp;#34;]) print(data_series) # 0 UCLA # 1 UC Berkeley # 2 UC Irvine # 3 University of Central Florida # 4 Rutgers University # dtype: object   # Convert a list of dictionaries into a dataframe states_dicts = [{&amp;#34;STATE&amp;#34;: &amp;#34;New Jersey&amp;#34;, &amp;#34;ABBREVIATION&amp;#34;: &amp;#34;NJ&amp;#34;},  {&amp;#34;STATE&amp;#34;: &amp;#34;New York&amp;#34;, &amp;#34;ABBREVIATION&amp;#34;: &amp;#34;NY&amp;#34;}]  states_df = pd.</description>
    </item>
    
    <item>
      <title>03. Line and Bar  👩‍🎓👨‍🎓</title>
      <link>/01-excel/activities/day-03/03-line-and-bar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/03-line-and-bar/</guid>
      <description>Line and Bar Grades For this activity, you’ll take on the role of the teacher as you create bar and line graphs to visualize your class’s grades over a semester.
Instructions   Create a series of bar graphs that visualize the grades of all students in the class, with one graph for every month.
  Create a line graph using all available data to compare students&amp;rsquo; grades over the semester.</description>
    </item>
    
    <item>
      <title>03. Manipulating Response  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-01/03-manipulating-responses/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/03-manipulating-responses/</guid>
      <description># Dependencies import requests import json  # Performing a GET Request and saving the  # API&amp;#39;s response within a variable url = &amp;#34;https://api.spacexdata.com/v2/rockets/falcon9&amp;#34; response = requests.get(url) response_json = response.json() print(json.dumps(response_json, indent=4, sort_keys=True))  # It is possible to grab a specific value  # from within the JSON object print(response_json[&amp;#34;cost_per_launch&amp;#34;])  # It is also possible to perform some # analyses on values stored within the JSON object number_payloads = len(response_json[&amp;#34;payload_weights&amp;#34;]) print(f&amp;#34;There are {number_payloads}payloads.</description>
    </item>
    
    <item>
      <title>03. Open Weather Request  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-02/03-open-weather-request/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/03-open-weather-request/</guid>
      <description> # Dependencies import json import requests from config import api_key # Save config information url = &amp;#34;http://api.openweathermap.org/data/2.5/weather?&amp;#34; city = &amp;#34;London&amp;#34;  # Build query URL query_url = url + &amp;#34;appid=&amp;#34; + api_key + &amp;#34;&amp;amp;q=&amp;#34; + city # Get weather data weather_response = requests.get(query_url) weather_json = weather_response.json()  # Get the temperature from the response print(f&amp;#34;The weather API responded with: {weather_json}.&amp;#34;) </description>
    </item>
    
    <item>
      <title>03. Pandas CSS Scrape 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-02/03-pandas-css-scrape/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-02/03-pandas-css-scrape/</guid>
      <description>Pandas Scrape In this activity, you will use BeautifulSoup to extract information from a simplified version of the official Pandas website.
Instructions   Follow these steps to set up for web scraping:
  Create a new Jupyter notebook and import BeautifulSoup.
  Copy and paste the code of the provided HTML file into a Python string.
  Create an instance of BeautifulSoup to parse the HTML.</description>
    </item>
    
    <item>
      <title>03. Pull 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-02/03-merge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-02/03-merge/</guid>
      <description></description>
    </item>
    
    <item>
      <title>03. Read SQL 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-01/03-read-sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/03-read-sql/</guid>
      <description># Pandas import pandas as pd  # SQL Alchemy from sqlalchemy import create_engine  database_path = &amp;#34;./Resources/Census_Data.sqlite&amp;#34;  # Create Engine engine = create_engine(f&amp;#34;sqlite:///{database_path}&amp;#34;) conn = engine.connect()  # Query All Records in the the Database data = pd.read_sql(&amp;#34;SELECT * FROM Census_Data&amp;#34;, conn) # Preview the Data data.head() </description>
    </item>
    
    <item>
      <title>03. Scrape Book Links 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-03/03-scrape-book-links/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-03/03-scrape-book-links/</guid>
      <description>Scrape Book Links In this activity, you&amp;rsquo;ll practice automated scraping on another website that was created specifically for practicing our skills: Books to Scrape.
Inspect the Website You&amp;rsquo;ll be scraping the links associated with each of the books on this website, so get started by using DevTools to review the details for each book.
  First, open up the website in Chrome and familiarize yourself with the page layout. Where can you find a link to more details about each book?</description>
    </item>
    
    <item>
      <title>03. Settlements Plotting Pandas 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-02/03-settlements-plotting-pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/03-settlements-plotting-pandas/</guid>
      <description>Union Settlements In this activity, you will use a dataset of 523 partial records, reduced from 13,758 total records, about major collective bargaining settlements in 1995. The Access to Archival Databases (AAD) limits downloads to 1,000 records, so this collection was reduced to the following unions: Actors Equity Association (AEA), Air Line Pilots (ALPA), Auto Workers (UAW), Bakery, Confectionery Workers International Union of America (BCW), Clothing and Textile Workers (ACTWU), and Elevator Constructors (IUEC).</description>
    </item>
    
    <item>
      <title>03. Stanger Height TTest 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-03/03-stranger-heights-ttest/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-03/03-stranger-heights-ttest/</guid>
      <description></description>
    </item>
    
    <item>
      <title>03. Summary Statistics 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-03/03-summary-statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/03-summary-statistics/</guid>
      <description>Summary Statistics in Python In this activity, you will be tasked with calculating a number of summary statistics using California housing data.
Instructions   Using Pandas, import the California housing dataset from the Resources folder.
  Determine the most appropriate measure of central tendency to describe the population, and then calculate this value.
  Use both data visualization and a quantitative measurement to find whether the age of houses in California is considered normally distributed using a small and large portion of the dataset.</description>
    </item>
    
    <item>
      <title>03. Creating Tables 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-01/03-creating-tables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/03-creating-tables/</guid>
      <description>In this activity, you will use pgAdmin to recreate and query a table based on an image provided to you.
Instructions   Create a new database in pgAdmin named city_info.
  Using the query tool, create an empty table named cities. Be sure to match the data types!
  Insert data into the new table. The result should match the following image.
   citycharacter varying (30) statecharacter varying (30) populationinteger     Alameda California 79177   Mesa Arizona 496401   Boerne Texas 16056   Anaheim California 352497   Tucson Arizona 535677   Garland Texas 238002      Query the table to recreate the image below.</description>
    </item>
    
    <item>
      <title>04. </title>
      <link>/10-advanced-sql/activities/day-03/04/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/04/</guid>
      <description></description>
    </item>
    
    <item>
      <title>04.  DataFrame Pandas 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-01/04-dataframe-pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/04-dataframe-pandas/</guid>
      <description>In this activity, you will create DataFrames from scratch using both a list of dictionaries and a dictionary of lists.
Instructions   Create a DataFrame for a frame shop. The DataFrame should contain three columns, &amp;ldquo;Frame&amp;rdquo;, &amp;ldquo;Price&amp;rdquo;, and &amp;ldquo;Sales&amp;rdquo;, and have five rows of data stored within it.
  Using an alternative method, create a DataFrame for an art gallery. The DataFrame should contain three columns, &amp;ldquo;Painting&amp;rdquo;, &amp;ldquo;Price&amp;rdquo;, and &amp;ldquo;Popularity&amp;rdquo;, and have four rows of data stored within it.</description>
    </item>
    
    <item>
      <title>04.  House of pies  👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-02/04-house-of-pies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/04-house-of-pies/</guid>
      <description>In this activity, you will build an order form that displays a list of pies and then prompts users to make a selection. The form will continue to prompt for selections until the user decides to end the process.
Instructions  Create an order form that displays a list of pies to the user in the following way:  Welcome to the House of Pies! Here are our pies: --------------------------------------------------------------------- (1) Pecan, (2) Apple Crisp, (3) Bean, (4) Banoffee, (5) Black Bun, (6) Blueberry, (7) Buko, (8) Burek, (9) Tamale, (10) Steak   Then, prompt the user to enter the number for the pie they would like to order.</description>
    </item>
    
    <item>
      <title>04.  Loop Conditional 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-02/04-loop-conditionals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-02/04-loop-conditionals/</guid>
      <description>conditional Sub conditional_loops()   &amp;#39; Create a for loop from 1 to 10  For i = 1 To 10   &amp;#39; Use the modulus function to determine if a number is divisible by 2 (even number)  If Cells(i, 1).Value Mod 2 = 0 Then   &amp;#39; Enter &amp;#34;Even Row&amp;#34; the adjacent cell  Cells(i, 2).Value = &amp;#34;Even Row&amp;#34;   &amp;#39; If the number is not divisible by 2 (odd number)  Else   &amp;#39; Enter &amp;#34;Even Row&amp;#34; the adjacent cell  Cells(i, 2).</description>
    </item>
    
    <item>
      <title>04.  Movie Ratings Binning  👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-03/04-movie-ratings-binning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-03/04-movie-ratings-binning/</guid>
      <description>Binning Movies In this activity, you will test your binning skills by creating bins for movies based on their IMDb user vote count.
Instructions   Read in the CSV file provided, and print it to the screen.
  Find the minimum &amp;ldquo;IMDB user vote count&amp;rdquo; and maximum &amp;ldquo;IMDB user vote count&amp;rdquo;.
  Using the minimum and maximum &amp;ldquo;votes&amp;rdquo; as a reference, create 9 bins to slice the data into.</description>
    </item>
    
    <item>
      <title>04. Anova 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-03/04-anova/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-03/04-anova/</guid>
      <description>import warnings warnings.filterwarnings(&amp;#39;ignore&amp;#39;) %matplotlib inline import pandas as pd import scipy.stats as stats  # Comparison of 5 Durations of Workouts # The problem: How do we know if working out on a regular basis will reduce overall average resting heart rate?  # The solution: ANOVA - does working out more regularly reduce average resting heart rate?  # Dataset: resting_heart_rate.csv # Source: Internally generated data.  # Description: Comparison of people who work out during the week and average resting heart rate.</description>
    </item>
    
    <item>
      <title>04. Branches 👩‍🎓👨‍🎓</title>
      <link>/07-project-1-part-1/activities/day-01/04-branch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-01/04-branch/</guid>
      <description></description>
    </item>
    
    <item>
      <title>04. Burundi Weather App 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-02/04-burundi-weather-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/04-burundi-weather-app/</guid>
      <description>Weather in Bujumbura This activity gives students practice with making API calls and handling responses.
Instructions   Save all of your &amp;ldquo;config&amp;rdquo; information—i.e., your API key; the base URL; etc.—before moving on.
  Build your query URL.
  Hint: Check the documentation to figure out how to request temperatures in Celsius.
  Make your request, and save the API response.
  Retrieve the current temperature in Bujumbura from the JSON response.</description>
    </item>
    
    <item>
      <title>04. Checkerboard layout 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-03/04-checkerboard-layout/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-03/04-checkerboard-layout/</guid>
      <description>Checkerboard Layout In this activity, you will work with a partner to create a checkerboard.
Instructions Using VBA scripts, create an 8-by-8 grid with alternating red and black squares.
Hints   You will need to use nested for loops, conditionals, the MOD function, and formatting to create the board.
  This is a tricky problem! Try to pseudocode a plan first.
  Unlike previous activities, this one can be solved in many different ways.</description>
    </item>
    
    <item>
      <title>04. Choose Your Button 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-01/04-choose-your-button/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/04-choose-your-button/</guid>
      <description>Choose Your Button In this activity, you’ll get to practice creating subroutines that can be triggered with the click of a button.
Instructions   Create an Excel file with two buttons.
  For each button, create a different VBA subroutine that will trigger a different pop-up message when clicked.
  If you finish early, ensure the people around you complete the task as well.
  —</description>
    </item>
    
    <item>
      <title>04. Cleaning Appliance Data 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-02/04-cleaning-appliance-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/04-cleaning-appliance-data/</guid>
      <description>Hong Kong LPG Appliances In this activity, you will take an LPG appliance dataset from Hong Kong, and clean it up so that the DataFrame is consistent and does not have any rows with missing data.
Instructions   Read in the CSV using Pandas, and print out the DataFrame that is returned.
 Note: This dataset uses Chinese characters and should be read in using UTF-8 encoding.    Reduce the DataFrame to only the columns in English.</description>
    </item>
    
    <item>
      <title>04. CRUD 👩‍🎓👨‍🎓</title>
      <link>/10-advanced-sql/activities/day-02/04-crud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-02/04-crud/</guid>
      <description>CRUD Database In this activity, you and a partner will practice CRUD operations with a new SQLite database.
Instructions   Within a Python file, create a new SQLAlchemy class called Travel to hold the following values:
  __tablename__: This should be &amp;ldquo;travel_destinations&amp;rdquo;
  id: The primary key for the table, which is an integer and automatically increments
  city: A string of the name of the city</description>
    </item>
    
    <item>
      <title>04. DevTools 👩‍🏫🧑‍🏫</title>
      <link>/11-data-collection/activities/day-02/04-devtools/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-02/04-devtools/</guid>
      <description>!pip install webdriver-manager  # This version uses selenium  from selenium import webdriver from bs4 import BeautifulSoup from webdriver_manager.chrome import ChromeDriverManager  # Set up using selenium browser = webdriver.Chrome(ChromeDriverManager().install())  url = &amp;#34;https://stackoverflow.com/questions/tagged/python?sort=MostVotes&amp;amp;edited=true&amp;#34;  browser.get(url)  html = browser.page_source  soup = BeautifulSoup(html, &amp;#39;html.parser&amp;#39;)  soup.find(&amp;#39;h1&amp;#39;).text  soup.find(&amp;#39;h1&amp;#39;).text.strip()  questions = soup.find_all(&amp;#39;a&amp;#39;, class_=&amp;#34;s-link&amp;#34;)  questions  for question in questions:  print(question[&amp;#39;class&amp;#39;])  questions = [question for question in questions if question[&amp;#39;class&amp;#39;]==[&amp;#39;s-link&amp;#39;]] questions  questions[0][&amp;#39;href&amp;#39;]  questions[0].</description>
    </item>
    
    <item>
      <title>04. Foreign Keys 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-03/04-foreign-keys/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/04-foreign-keys/</guid>
      <description>In this activity, you will create and populate three new tables with foreign keys that reference existing data.
Instructions   Create a new database named business_DB to use with this activity.
  Make sure all tables have primary keys that increment with each new row of data.
    Create a customer table with a customer first name and customer last name.
  Populate the customer table with customer names.</description>
    </item>
    
    <item>
      <title>04. Grade Book 👩‍🎓👨‍🎓</title>
      <link>/01-excel/activities/day-02/04-grade-book/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/04-grade-book/</guid>
      <description>Grade Book One of the most common uses of Excel in academia is keeping track of students&amp;rsquo; grades. In this activity, you and your partner will create a spreadsheet that averages out the scores for students in a fictional class and then determines whether each student has passed or failed the course.
Instructions The solved should look closely to this:
  Create a formula that calculates the final grade for a student based upon their previous exams and papers.</description>
    </item>
    
    <item>
      <title>04. Hello Variable World 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-01/04-hello-variable-world/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/04-hello-variable-world/</guid>
      <description>Hello, Variable World In this activity, you will create a simple Python application that uses variables to run calculations on integers and print strings out to the console.
Instructions   Create two variables, called name and country, that will hold strings.
  Create two variables, called age and hourly_wage, that will hold integers.
  Create a variable called satisfied, which will hold a Boolean.
  Create a variable called daily_wage, which will hold the value of hourly_wage multiplied by 8.</description>
    </item>
    
    <item>
      <title>04. Legendary Temperature 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-01/04-legendary-temperature/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/04-legendary-temperature/</guid>
      <description>Legendary Temperature In this activity, you will expand upon your temperature plots to add a legend.
Instructions   Modify the New Jersey temperature line charts from earlier so that they match the image provided.
  Once the plot has been created, check the Matplotlib documentation to see what additional formatting could be added to the chart.
   ✅ Solutions   Solutions Click Here    # Include this line to make plots interactive %matplotlib notebook # Dependencies import matplotlib.</description>
    </item>
    
    <item>
      <title>04. List Comprehensions 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-03/04-list-comprehensions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/04-list-comprehensions/</guid>
      <description>fish = &amp;#34;halibut&amp;#34;  # Loop through each letter in the string # and push to an array letters = [] for letter in fish:  letters.append(letter)  print(letters)  # List comprehensions provide concise syntax for creating lists letters = [letter for letter in fish]  print(letters)  # We can manipulate each element as we go capital_letters = [] for letter in fish:  capital_letters.append(letter.upper())  print(capital_letters)  # List Comprehension for the above capital_letters = [letter.</description>
    </item>
    
    <item>
      <title>04. Nearest Restaurants  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-03/04-nearest-restaurants/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/04-nearest-restaurants/</guid>
      <description></description>
    </item>
    
    <item>
      <title>04. News 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-03/04-news/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-03/04-news/</guid>
      <description>News Scraping  In this activity, you will scrape news summaries across multiple pages from the Global Voices news site.  Instructions   Open page 2 of Global Voices news. Use DevTools to identify the elements that contain the data you need to scrape.
  Within your Jupyter notebook, use Splinter to click on any popup or lightbox to make it disappear.
  Create an empty list to store your article summaries.</description>
    </item>
    
    <item>
      <title>04. Order by  👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-02/04-order-by/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/04-order-by/</guid>
      <description>-- Select the average length of movies by rental rate SELECT rental_rate, AVG(length) AS &amp;#34;avg length&amp;#34; FROM film GROUP BY rental_rate ORDER BY &amp;#34;avg length&amp;#34;;  -- Round the results to use only two decimal places SELECT rental_rate, ROUND(AVG(length),2) AS &amp;#34;avg length&amp;#34; FROM film GROUP BY rental_rate ORDER BY &amp;#34;avg length&amp;#34;;  -- Order by descending values SELECT rental_rate, ROUND(AVG(length),2) AS &amp;#34;avg length&amp;#34; FROM film GROUP BY rental_rate ORDER BY &amp;#34;avg length&amp;#34; DESC;  -- Limit results to 5 SELECT rental_rate, ROUND(AVG(length),2) AS &amp;#34;avg length&amp;#34; FROM film GROUP BY rental_rate ORDER BY &amp;#34;avg length&amp;#34; DESC LIMIT 5; </description>
    </item>
    
    <item>
      <title>04. Pull Request 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-02/04-pull-requests/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-02/04-pull-requests/</guid>
      <description></description>
    </item>
    
    <item>
      <title>04. Read All the SQLs 👩‍🎓👨‍🎓</title>
      <link>/10-advanced-sql/activities/day-01/04-read-all-the-sqls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/04-read-all-the-sqls/</guid>
      <description>In this activity, you will query an external server by using Pandas and SQLAlchemy to create new DataFrames on U.S. Census data.
Instructions   Create an engine to connect to the Census database.
  Query all the data from the Census_Data table, and load it into Pandas.
  Create an engine to connect to the zip database.
  Query all the data from the Zip_Census table, and load it in Pandas.</description>
    </item>
    
    <item>
      <title>04. Requesting a Galaxy Far Far Away 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-01/04-farfaraway-apidata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/04-farfaraway-apidata/</guid>
      <description>Requesting a Galaxy Far Far Away In this activity you will create an application that accesses data from the Star Wars API and prints out values from within it.
Instructions   Using the starter file provided, collect the following pieces of information from the Star Wars API.
  The name of the character
  The number of films they were in
  The name of their first starship</description>
    </item>
    
    <item>
      <title>04. Scatter plot 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-03/04-scatter-plot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/04-scatter-plot/</guid>
      <description>Open 04-Ins_ScatterPlot/ScatterPlot.xlsx in Excel, navigate into the &amp;ldquo;Normal Trend&amp;rdquo; worksheet, and we can use a scatter plot to compare an individual&amp;rsquo;s salary to the price of their car.
  PC steps
  Adding a trend line to a chart is a quick process. Click the plus symbol to the right of your selected chart, then, under “Chart Elements”, select the &amp;ldquo;Trendline&amp;rdquo; option, as in the following image:</description>
    </item>
    
    <item>
      <title>04. Soup to Nuts 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-01/04-soup-to-nuts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-01/04-soup-to-nuts/</guid>
      <description>From Soup to Nuts   In this activity, you will perform basic scraping of HTML.
  Create a new Jupyter notebook, and import BeautifulSoup into it.
  Open html-tags.html in VS Code. Copy and paste the code into your Jupyter notebook as a Python string. Use triple quotation marks, as it will be a multi-line string.
  html = &amp;#34;&amp;#34;&amp;#34; &amp;lt;html code&amp;gt; &amp;#34;&amp;#34;&amp;#34;   Parse the HTML code with BeautifulSoup.</description>
    </item>
    
    <item>
      <title>04. Standard Error 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-03/04-standard-error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/04-standard-error/</guid>
      <description># Dependencies import pandas as pd import random import matplotlib.pyplot as plt import numpy as np from scipy.stats import sem  # Set the seed so our data is reproducible random.seed(42) # Sample versus population example fuel economy fuel_economy = pd.read_csv(&amp;#39;../Resources/2019_fuel_economy.csv&amp;#39;)  # First overview the data set - how many factors, etc. print(fuel_economy.head())  # Calculate the summary statistics and plot the histogram of the entire population data print(f&amp;#34;The mean MPG of all vehicles is: {round(fuel_economy[&amp;#39;Combined_MPG&amp;#39;].</description>
    </item>
    
    <item>
      <title>05. Making IDs 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-01/05-making-ids/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/05-making-ids/</guid>
      <description>Making and Using an ID In this activity, you will recreate a table and then query, insert, and update data.
Instructions   Create a new database named programming_db.
  Recreate the programming_languages table using the following image.
   idinteger languagecharacter varying (20) ratinginteger     1 HTML 95   2 JS 99   3 JQuery 98   4 MySQL 70   5 MySQL 70      Query the table to return the rows containing MySQL, and then delete one of the duplicates.</description>
    </item>
    
    <item>
      <title>04. Values of Uniques 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-01/04-values-of-uniques/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/04-values-of-uniques/</guid>
      <description>-- Delete the table &amp;#34;people&amp;#34; DROP TABLE people;  -- Re-create the table &amp;#34;people&amp;#34; within animals_db CREATE TABLE people (  id SERIAL PRIMARY KEY,  name VARCHAR(30) NOT NULL,  has_pet BOOLEAN DEFAULT false,  pet_type VARCHAR(10) NOT NULL,  pet_name VARCHAR(30),  pet_age INT );  -- Insert data into the table INSERT INTO people (name, has_pet, pet_type, pet_name, pet_age) VALUES (&amp;#39;Jacob&amp;#39;, true, &amp;#39;dog&amp;#39;, &amp;#39;Misty&amp;#39;, 10),  (&amp;#39;Ahmed&amp;#39;, true, &amp;#39;rock&amp;#39;, &amp;#39;Rockington&amp;#39;, 100),  (&amp;#39;Ahmed&amp;#39;, true, &amp;#39;rock&amp;#39;, &amp;#39;Rockington&amp;#39;, 100),  (&amp;#39;Peter&amp;#39;, true, &amp;#39;cat&amp;#39;, &amp;#39;Franklin&amp;#39;, 2),  (&amp;#39;Dave&amp;#39;, true, &amp;#39;dog&amp;#39;, &amp;#39;Queso&amp;#39;, 1),  (&amp;#39;Dave&amp;#39;, true, &amp;#39;dog&amp;#39;, &amp;#39;Pringles&amp;#39;, 7);  -- Query all fields from the table SELECT * FROM people;  -- Query the data to return all the rows containing the name &amp;#34;Dave&amp;#34; SELECT id, name, pet_name, pet_age FROM people WHERE name = &amp;#39;Dave&amp;#39;;  -- Update a single row to change the `pet_name` and `pet_age` column data UPDATE people SET has_pet = true, pet_name = &amp;#39;Rocket&amp;#39;, pet_age = 8 WHERE id = 6;  SELECT * FROM people;  -- Delete the duplicate entry using a unique id DELETE FROM people WHERE id = 3;  SELECT * FROM people; </description>
    </item>
    
    <item>
      <title>05. </title>
      <link>/10-advanced-sql/activities/day-03/05/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/05/</guid>
      <description></description>
    </item>
    
    <item>
      <title>05.  Basic Read 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-02/05-basic-read/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/05-basic-read/</guid>
      <description># Store the file path associated with the file (note the backslash may be OS specific) file = &amp;#39;./Resources/input.txt&amp;#39;  # Open the file in &amp;#34;read&amp;#34; mode (&amp;#39;r&amp;#39;) and store the contents in the variable &amp;#34;text&amp;#34; with open(file, &amp;#39;r&amp;#39;) as text:   # This stores a reference to a file stream  print(text)   # Store all of the text inside a variable called &amp;#34;lines&amp;#34;  lines = text.</description>
    </item>
    
    <item>
      <title>05.  Data Functions 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-01/05-data-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/05-data-functions/</guid>
      <description># Dependencies import pandas as pd  # Save path to data set in a variable data_file = &amp;#34;./Resources/dataSet.csv&amp;#34;  # Use Pandas to read data data_file_df = pd.read_csv(data_file) data_file_df.head()  # Display a statistical overview of the DataFrame data_file_df.describe()  # Reference a single column within a DataFrame data_file_df[&amp;#34;Amount&amp;#34;].head()  # Reference multiple columns within a DataFrame data_file_df[[&amp;#34;Amount&amp;#34;, &amp;#34;Gender&amp;#34;]].head()  # The mean method averages the series average = data_file_df[&amp;#34;Amount&amp;#34;].</description>
    </item>
    
    <item>
      <title>05.  Mapping 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-03/05-mapping/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-03/05-mapping/</guid>
      <description> import pandas as pd # Mapping lets you format an entire DataFrame file = &amp;#34;Resources/Seattle_Housing_Cost_Burden.csv&amp;#34; file_df = pd.read_csv(file) file_df.head()  # Use Map to format all the columns file_df[&amp;#34;INCOME&amp;#34;] = file_df[&amp;#34;INCOME&amp;#34;].map(&amp;#34;${:,.2f}&amp;#34;.format) file_df[&amp;#34;COSTS&amp;#34;] = file_df[&amp;#34;COSTS&amp;#34;].map(&amp;#34;${:,.2f}&amp;#34;.format) file_df[&amp;#34;PERCENT30&amp;#34;] = (file_df[&amp;#34;PERCENT30&amp;#34;]*100).map(&amp;#34;{:.1f}%&amp;#34;.format) file_df[&amp;#34;PERCENT3050&amp;#34;] = (file_df[&amp;#34;PERCENT3050&amp;#34;]*100).map(&amp;#34;{:.1f}%&amp;#34;.format) file_df[&amp;#34;PERCENT50&amp;#34;] = (file_df[&amp;#34;PERCENT50&amp;#34;]*100).map(&amp;#34;{:.1f}%&amp;#34;.format) file_df[&amp;#34;PERCENT_NODATA&amp;#34;] = (file_df[&amp;#34;PERCENT_NODATA&amp;#34;]*100).map(&amp;#34;{:.1f}%&amp;#34;.format) file_df[&amp;#34;PERCENT_NOBURDEN&amp;#34;] = (file_df[&amp;#34;PERCENT_NOBURDEN&amp;#34;]*100).map(&amp;#34;{:.1f}%&amp;#34;.format) file_df[&amp;#34;TOTAL&amp;#34;] = file_df[&amp;#34;TOTAL&amp;#34;].map(&amp;#34;{:,}&amp;#34;.format) file_df.head()  # Mapping has changed the datatypes of the columns to strings file_df.dtypes </description>
    </item>
    
    <item>
      <title>05.  Prompts 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-01/05-prompts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/05-prompts/</guid>
      <description># Collects the user&amp;#39;s input for the prompt &amp;#34;What is your name?&amp;#34; name = input(&amp;#34;What is your name? &amp;#34;)  # Collects the user&amp;#39;s input for the prompt &amp;#34;How old are you?&amp;#34; and converts the string to an integer. age = int(input(&amp;#34;How old are you? &amp;#34;))  # Collects the user&amp;#39;s input for the prompt &amp;#34;Is input truthy?&amp;#34; and converts it to a boolean. Note that non-zero, # non-empty objects are truth-y.</description>
    </item>
    
    <item>
      <title>05. Aesthetics 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-01/05-aesthetics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/05-aesthetics/</guid>
      <description>%matplotlib notebook  # Dependencies import matplotlib.pyplot as plt import numpy as np # Generate the x values from 0 to 10 using a step of 0.1 x_axis = np.arange(0, 10, 0.1) sin = np.sin(x_axis) cos = np.cos(x_axis) # Add a semi-transparent horizontal line at y = 0 plt.hlines(0, 0, 10, alpha=0.25)   # Use dots or other markers for your plots, and change their colors plt.plot(x_axis, sin, linewidth=0, marker=&amp;#34;o&amp;#34;, color=&amp;#34;blue&amp;#34;) plt.</description>
    </item>
    
    <item>
      <title>05. Anova 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-03/05-anova/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-03/05-anova/</guid>
      <description></description>
    </item>
    
    <item>
      <title>05. Cells and Ranges 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-01/05-cells-and-ranges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/05-cells-and-ranges/</guid>
      <description>Sub CellsAndRanges():   &amp;#39; Inserting Data Via Cells  Cells(2, 1).Value = &amp;#34;Cat&amp;#34;  Cells(2, 2).Value = &amp;#34;In&amp;#34;  Cells(2, 3).Value = &amp;#34;The&amp;#34;  Cells(2, 4).Value = &amp;#34;Hat&amp;#34;   &amp;#39; Inserting Data Via Ranges  Range(&amp;#34;F1&amp;#34;).Value = &amp;#34;I&amp;#34;  Range(&amp;#34;F2&amp;#34;).Value = &amp;#34;Am&amp;#34;  Range(&amp;#34;F3&amp;#34;).Value = &amp;#34;Sam&amp;#34;   &amp;#39; Inserting Data Across Ranges  Range(&amp;#34;F5:F7&amp;#34;).Value = 5  End Sub </description>
    </item>
    
    <item>
      <title>05. Central Tendency 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/05-central-tendency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/05-central-tendency/</guid>
      <description>File:
  05-Ins_CentralTendency/CentralTendency.xlsx
  Measures of central tendency are some of the most basic concepts in statistics.
  measures of central tendency are values that describe a dataset. More specifically, the measures of central tendency describe the center of a dataset.
  The most common measures of central tendency are the mean, median, and mode.
  mean of a dataset is also referred to as the arithmetic average of a dataset.</description>
    </item>
    
    <item>
      <title>05. CSS 👩‍🏫🧑‍🏫</title>
      <link>/11-data-collection/activities/day-01/05-css/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-01/05-css/</guid>
      <description>css demo 01 &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;en&amp;#34;&amp;gt;  &amp;lt;head&amp;gt;  &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt;  &amp;lt;meta http-equiv=&amp;#34;X-UA-Compatible&amp;#34; content=&amp;#34;IE=edge&amp;#34;&amp;gt;  &amp;lt;meta name=&amp;#34;viewport&amp;#34; content=&amp;#34;width=device-width, initial-scale=1.0&amp;#34;&amp;gt;  &amp;lt;title&amp;gt;Document&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt;  &amp;lt;body&amp;gt;   &amp;lt;p&amp;gt;I&amp;#39;m first!&amp;lt;/p&amp;gt;  &amp;lt;p&amp;gt;I&amp;#39;m second!&amp;lt;/p&amp;gt;   &amp;lt;p&amp;gt;I&amp;#39;m third!&amp;lt;/p&amp;gt;  &amp;lt;p&amp;gt;I&amp;#39;m fourth!&amp;lt;/p&amp;gt;  &amp;lt;/body&amp;gt;  &amp;lt;/html&amp;gt; css demo 02 &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;en&amp;#34;&amp;gt;  &amp;lt;head&amp;gt;  &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt;  &amp;lt;meta http-equiv=&amp;#34;X-UA-Compatible&amp;#34; content=&amp;#34;IE=edge&amp;#34;&amp;gt;  &amp;lt;meta name=&amp;#34;viewport&amp;#34; content=&amp;#34;width=device-width, initial-scale=1.0&amp;#34;&amp;gt;  &amp;lt;title&amp;gt;Document&amp;lt;/title&amp;gt;   &amp;lt;style&amp;gt;   &amp;lt;/style&amp;gt;  &amp;lt;/head&amp;gt;  &amp;lt;body&amp;gt;   &amp;lt;div&amp;gt;  &amp;lt;p&amp;gt;I&amp;#39;m first!</description>
    </item>
    
    <item>
      <title>05. Data Relationships 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-03/05-data-relationships/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/05-data-relationships/</guid>
      <description>-- One to one -- Simpson table CREATE TABLE simpsons(  id SERIAL,  name VARCHAR,  &amp;#34;Social Security&amp;#34; INTEGER );  INSERT INTO simpsons (name, &amp;#34;Social Security&amp;#34;) VALUES  (&amp;#39;Homer&amp;#39;, 111111111),  (&amp;#39;Marge&amp;#39;, 222222222),  (&amp;#39;Lisa&amp;#39;, 333333333),  (&amp;#39;Bart&amp;#39;, 444444444),  (&amp;#39;Maggie&amp;#39;, 555555555);  -- One to Many -- Address Table CREATE TABLE address (  id INTEGER PRIMARY KEY,  address VARCHAR );  -- Insertion query for address table INSERT INTO address (id, address) VALUES  (11, &amp;#39;742 Evergreen Terrace&amp;#39;),  (12, &amp;#39;221b Baker Streer&amp;#39;);  -- People Table CREATE TABLE people (  id INTEGER PRIMARY KEY,  name VARCHAR,  social_security INTEGER,  address_id INTEGER );  -- Insertion query for people table INSERT INTO people (id, name, social_security) VALUES  (1, &amp;#39;Homer&amp;#39;, 111111111),  (2, &amp;#39;Marge&amp;#39;, 222222222),  (3, &amp;#39;Lisa&amp;#39;, 333333333),  (4, &amp;#39;Bart&amp;#39;, 444444444),  (5, &amp;#39;Maggie&amp;#39;, 555555555),  (6, &amp;#39;Sherlock&amp;#39;, 666666666),  (7, &amp;#39;Watson&amp;#39;, 777777777);  -- Many to Many -- Table schema for the Simpsons children CREATE TABLE children(  child_id SERIAL,  child_name VARCHAR(255) NOT NULL,  PRIMARY KEY (child_id) );  -- Insertion queries for the Simpsons children INSERT INTO children (child_name) VALUES  (&amp;#39;Bart&amp;#39;),  (&amp;#39;Lisa&amp;#39;),  (&amp;#39;Maggie&amp;#39;);  -- Table schema for the Simpsons parents CREATE TABLE parents(  parent_id INTEGER NOT NULL,  parent_name VARCHAR(255) NOT NULL,  PRIMARY KEY (parent_id) );  -- Insertion queries for the Simpsons parents INSERT INTO parents (parent_id, parent_name) VALUES  (11, &amp;#39;Homer&amp;#39;),  (12, &amp;#39;Marge&amp;#39;);  -- Table schema for the junction table CREATE TABLE child_parent (  child_id INTEGER NOT NULL,  FOREIGN KEY (child_id) REFERENCES children(child_id),  parent_id INTEGER NOT NULL,  FOREIGN KEY (parent_id) REFERENCES parents(parent_id),  PRIMARY KEY (child_id, parent_id) );  -- Insertion queries for the junction table INSERT INTO child_parent (child_id, parent_id) VALUES  (1, 11),  (1, 12),  (2, 11),  (2, 12),  (3, 11),  (3, 12);  -- Query children table SELECT * FROM children;  -- Query parents table SELECT * FROM parents;  -- Query child_parent table SELECT * FROM child_parent;  -- Query to display the many-to-many relationships SELECT children.</description>
    </item>
    
    <item>
      <title>05. Exploring Airports 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-03/05-exploring-airports/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/05-exploring-airports/</guid>
      <description>Exploring Airports in Australia In this activity, you&amp;rsquo;ll be tasked with obtaining information about some Australian airports. You&amp;rsquo;ll be given a list of cities, and you&amp;rsquo;ll need to use the Geoapify Geocoding API and Geoapify Places API to obtain the airports&amp;rsquo; information.
Instructions   Using airports.ipynb as a starting point, use the Geoapify Geocoding API, the Geoapify Places API, and Python to create a script that retrieves information of some Australian airports in each of the cities found in Cities.</description>
    </item>
    
    <item>
      <title>05. Fizz Buzz 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-02/05-fizz-buzz/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-02/05-fizz-buzz/</guid>
      <description>Fizz Buzz In this activity, you&amp;rsquo;ll work on a popular logic problem that countless coders have encountered in technical interviews.
Instructions Create a VBA script that populates the second column with the word &amp;ldquo;Fizz&amp;rdquo;, &amp;ldquo;Buzz&amp;rdquo;, or &amp;ldquo;Fizzbuzz&amp;rdquo; based on the value in the first column.
  If the value in Column 1 is a multiple of both 3 and 5, print &amp;ldquo;Fizzbuzz&amp;rdquo; in Column 2.
  If the value in Column 1 is a multiple of just 3, print &amp;ldquo;Fizz&amp;rdquo; in Column 2.</description>
    </item>
    
    <item>
      <title>05. Homesale Scatter plot 👩‍🎓👨‍🎓</title>
      <link>/01-excel/activities/day-03/05-homesales-scatterplots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/05-homesales-scatterplots/</guid>
      <description>Home Sales For this activity, you will work in pairs to create a series of scatter plots that compare home prices in the St. Louis, MO, region with different home attributes, including square footage, number of bedrooms, and number of bathrooms.
Instructions   Create a scatter plot that compares the price of the home with the square feet of the home (sqft_living). Make sure to add in axis titles, a chart title, and a trend line.</description>
    </item>
    
    <item>
      <title>05. Library Usage Groupby  👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-02/05-library-usage-groupby/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/05-library-usage-groupby/</guid>
      <description>Library Usage In this activity, you will create a pair of charts based on library usage collected from San Francisco. This dataset includes information on library patrons who became patrons of San Francisco Public Library between 2003 and 2016, and tracks their total library usage during that period.
Instructions   Open the starter file and follow the prompts to import, split, and summarize the library dataset.
  Create a bar chart by using Pandas and Matplotlib that visualizes how many patrons checked out items by patron type.</description>
    </item>
    
    <item>
      <title>05. List Comprehensions 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-03/05-list-comprehensions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/05-list-comprehensions/</guid>
      <description>In this activity, you’ll use list comprehensions to compose a wedding invitation, which you will send to every name on your mailing list.
Instructions   Fill the cell below.
  Run the provided program. Note that nothing forces you to write the name properly in title case—for example, as &amp;ldquo;Jane&amp;rdquo; instead of &amp;ldquo;jAnE&amp;rdquo;. You will use list comprehensions to fix this.
  First, use list comprehensions to create a new list that contains the lowercase version of each of the names your user provided.</description>
    </item>
    
    <item>
      <title>05. Mars Facts Scrape 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-03/05-mars-fact-scrape/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-03/05-mars-fact-scrape/</guid>
      <description>Mars Facts Scrape In this activity, you&amp;rsquo;ll practice scraping data that was stored in a table on a website.
Instructions   First, open up the Mars Facts website in Chrome and become familiar with the layout.
  You&amp;rsquo;ll scrape the data from the table labeled &amp;ldquo;Mars Planet Profile.&amp;rdquo; Use Chrome DevTools to inspect that element. What is the class of the table you want to scrape?
  Now that you know the class you are looking for, begin the scraping process by importing the necessary libraries and setting up Splinter.</description>
    </item>
    
    <item>
      <title>05. Next Cells 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-03/05-next-cells/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-03/05-next-cells/</guid>
      <description>Sub NextCells()   &amp;#39; Set a variable for specifying the column of interest  Dim column As Integer  column = 1   &amp;#39; Loop through rows in the column  For i = 2 To 6   &amp;#39; Searches for when the value of the next cell is different than that of the current cell  If Cells(i + 1, column).Value &amp;lt;&amp;gt; Cells(i, column).Value Then   &amp;#39; Message Box the value of the current cell and value of the next cell  MsgBox (Cells(i, column).</description>
    </item>
    
    <item>
      <title>05. Number Facts API 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-01/05-number-facts-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/05-number-facts-api/</guid>
      <description>Number Facts API In this activity, you’ll use Python to create a user-friendly way to get data from an API.
Instructions Using the Numbers API, create an application that takes in a user&amp;rsquo;s inputs and returns a number fact based upon it.
Hints   The URL to make your request must have ?json at its end so that the data format returned is JSON. The default response is pure text.</description>
    </item>
    
    <item>
      <title>05. Open Weather DataFrame  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-02/05-open-weather-data-frame/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/05-open-weather-data-frame/</guid>
      <description># Dependencies import matplotlib.pyplot as plt import requests import pandas as pd from config import api_key # Save config information. url = &amp;#34;http://api.openweathermap.org/data/2.5/weather?&amp;#34; units = &amp;#34;metric&amp;#34;  # Build partial query URL query_url = f&amp;#34;{url}appid={api_key}&amp;amp;units={units}&amp;amp;q=&amp;#34; cities = [&amp;#34;Paris&amp;#34;, &amp;#34;London&amp;#34;, &amp;#34;Oslo&amp;#34;, &amp;#34;Beijing&amp;#34;]  # set up lists to hold reponse info lat = [] temp = []  # Loop through the list of cities and perform a request for data on each for city in cities:  response = requests.</description>
    </item>
    
    <item>
      <title>05. Order By  👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-02/05-order-by/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/05-order-by/</guid>
      <description>Movies Ordered By In this activity, you will use ORDER BY in combination with other SQL methods to query and order the tables.
Instructions   Determine the count of actor first names with the names ordered in descending order.
  Determine the average rental duration for each rating rounded to two decimals. Order these in ascending order.
  Determine the top 10 average replacement costs for movies, ordered by their length.</description>
    </item>
    
    <item>
      <title>05. Pandas Recap 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-02/05-pandas-recap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/05-pandas-recap/</guid>
      <description>Pandas Recap and Data Types In this activity, we will recap what we have learned about Pandas up to this point.
Instructions   Open ‘PandasRecap.ipynb’ under the ‘unsolved’ folder in your Jupyter notebook.
  Go through the cells, and follow the instructions in the comments.
  Hints   A list of a DataFrame&amp;rsquo;s data types can be checked by accessing its dtypes property.
  To change a non-numeric column to a numeric column, use the df.</description>
    </item>
    
    <item>
      <title>05. Preview SQL Alchemy 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-01/05-preview-sql-alchemy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/05-preview-sql-alchemy/</guid>
      <description># Dependencies # ---------------------------------- from sqlalchemy import create_engine from sqlalchemy.ext.declarative import declarative_base Base = declarative_base() from sqlalchemy import Column, Integer, String, Float  # Create Dog and Cat Classes # ---------------------------------- class Dog(Base):  __tablename__ = &amp;#39;dog&amp;#39;  id = Column(Integer, primary_key=True)  name = Column(String(255))  color = Column(String(255))  age = Column(Integer)  class Cat(Base):  __tablename__ = &amp;#39;cat&amp;#39;  id = Column(Integer, primary_key=True)  name = Column(String(255))  color = Column(String(255))  age = Column(Integer)  # Create a Specific Instance of the Dog and Cat classes # ---------------------------------- dog = Dog(name=&amp;#34;Fido&amp;#34;, color=&amp;#39;Brown&amp;#39;, age=4) cat = Cat(name=&amp;#34;Whiskers&amp;#34;, color=&amp;#34;Gray&amp;#34;, age=7)  # Create Database Connection # ---------------------------------- database_path = &amp;#34;pets_db&amp;#34; engine = create_engine(f&amp;#34;sqlite:///{database_path}&amp;#34;) conn = engine.</description>
    </item>
    
    <item>
      <title>05. Push 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-01/05-push/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-01/05-push/</guid>
      <description></description>
    </item>
    
    <item>
      <title>05. Reflection 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-02/05-reflection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-02/05-reflection/</guid>
      <description># Python SQL toolkit and Object Relational Mapper import sqlalchemy from sqlalchemy.ext.automap import automap_base from sqlalchemy.orm import Session from sqlalchemy import create_engine  # Create engine using the `demographics.sqlite` database file engine = create_engine(&amp;#34;sqlite:///./resources/dow.sqlite&amp;#34;) # Declare a Base using `automap_base()` Base = automap_base() # Use the Base class to reflect the database tables Base.prepare(autoload_with=engine) # Print all of the classes mapped to the Base Base.classes.keys()  # Assign the dow class to a variable called `Dow` Dow = Base.</description>
    </item>
    
    <item>
      <title>05. SEM and Error Bars 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-03/05-sem-error-bars/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/05-sem-error-bars/</guid>
      <description>SEM and Error Bars In this activity, you will work with a partner to characterize sample data from a California housing dataset. Make sure to compare your calculated values as you progress through the activity.
Instructions Work with a partner on this activity. Be sure to compare your calculated values as you progress through the activity.
  Execute the starter code to import the California housing dataset from Scikit-learn.</description>
    </item>
    
    <item>
      <title>05. StackOverflow 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-02/05-stackoverflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-02/05-stackoverflow/</guid>
      <description>Stack Scrape In this activity, you will scrape Stack Overflow&amp;rsquo;s Python page and store the results in a Python list of dictionaries.
Instructions Visit Stack Overflow&amp;rsquo;s Python page with Splinter&amp;rsquo;s automated browser. Scrape information from all the questions on the first page. For each question, use BeautifulSoup to scrape the following pieces of information:
  The summary (e.g. &amp;lsquo;What does the &amp;ldquo;yield&amp;rdquo; keyword do?&amp;rsquo; for the first question)
  The number of votes for that question</description>
    </item>
    
    <item>
      <title>06. </title>
      <link>/10-advanced-sql/activities/day-03/06/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/06/</guid>
      <description></description>
    </item>
    
    <item>
      <title>06.  Cleaning Crowdfunding  👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-03/06-cleaning-crowdfunding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-03/06-cleaning-crowdfunding/</guid>
      <description>Cleaning Crowdfunding In this activity, you will take the dataset from your first homework, clean it up, and format it.
Instructions  The instructions for this activity are contained within the Jupyter notebook.  References Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.
 ✅ Solutions   Solutions Click Here    import pandas as pd # The path to our CSV file file = &amp;#34;Resources/CrowdfundingData.</description>
    </item>
    
    <item>
      <title>06.  Group By 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-02/06-group-by/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/06-group-by/</guid>
      <description># Import the Pandas library import pandas as pd # Create a reference the CSV file desired csv_path = &amp;#34;Resources/CT_fires_2015.csv&amp;#34;  # Read the CSV into a Pandas DataFrame fires_df = pd.read_csv(csv_path)  # Print the first five rows of data to the screen fires_df.head()  	# Rename mistyped columns &amp;#34;Propery Loss&amp;#34; fires_df = fires_df.rename(columns={&amp;#34;Propery Loss&amp;#34;: &amp;#34;Property Loss&amp;#34;})  # Reduce to columns: Fire Department Name, Incident date, Incident Type Code, Incident Type, # Alarm Date and Time, Arrival Date and Time, Last Unit Cleared Date and Time,  # Property Loss, Contents Loss, Fire Service Deaths, Fire Service Injuries,  # Other Fire Deaths, Other Fire Injuries, Incident City, Incident Zip Code  fires_reduced = fires_df[[&amp;#34;Fire Department Name&amp;#34;, &amp;#34;Incident date&amp;#34;, &amp;#34;Incident Type Code&amp;#34;,  &amp;#34;Incident Type&amp;#34;, &amp;#34;Alarm Date and Time&amp;#34;, &amp;#34;Arrival Date and Time&amp;#34;,  &amp;#34;Last Unit Cleared Date and Time&amp;#34;, &amp;#34;Property Loss&amp;#34;, &amp;#34;Contents Loss&amp;#34;,  &amp;#34;Fire Service Deaths&amp;#34;, &amp;#34;Fire Service Injuries&amp;#34;, &amp;#34;Other Fire Deaths&amp;#34;,  &amp;#34;Other Fire Injuries&amp;#34;, &amp;#34;Incident City&amp;#34;, &amp;#34;Incident Zip Code&amp;#34;]] fires_reduced.</description>
    </item>
    
    <item>
      <title>06.  Module 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-02/06-module/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/06-module/</guid>
      <description># Import the random and string Module import random import string  # Utilize the string module&amp;#39;s custom method: &amp;#34;.ascii_letters&amp;#34; print(string.ascii_letters)  # Utilize the random module&amp;#39;s custom method randint for x in range(10):  print(random.randint(1, 10)) </description>
    </item>
    
    <item>
      <title>06.  Training Grounds 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-01/06-training-grounds-data-funtions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/06-training-grounds-data-funtions/</guid>
      <description>In this activity, you will take a large DataFrame containing 200 rows, analyze it with data functions, and then add a new column into it.
Instructions Using the DataFrame provided, perform all of the following actions:
  Provide a simple analytical overview of the dataset&amp;rsquo;s numeric columns.
  Collect all of the names of the trainers within the dataset.
  Figure out how many students each trainer has.</description>
    </item>
    
    <item>
      <title>06. Chessboard  👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-01/06-chessboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/06-chessboard/</guid>
      <description>Chessboard For this activity, you&amp;rsquo;ll add the names of chess pieces to their starting positions on the provided chessboard.
Instructions  Add text-based chess pieces to the provided chessboard. For the first two rows of the chessboard, use Ranges; for the final two rows of the chessboard, use Cells.  Piece positions:
   Rook Knight Bishop Queen King Bishop Knight Rook     Pawn Pawn Pawn Pawn Pawn Pawn Pawn Pawn                                               Pawn Pawn Pawn Pawn Pawn Pawn Pawn Pawn   Rook Knight Bishop Queen King Bishop Knight Rook    Hint Remember that with Ranges, it is possible to modify multiple cells at once.</description>
    </item>
    
    <item>
      <title>06. Chi Square 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-03/06-chi-square/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-03/06-chi-square/</guid>
      <description>import numpy as np import pandas as pd # The statistical module used to run chi square test import scipy.stats as stats # Observed data in a (hypothetical) survey of 300 people  observed = pd.Series([220,55,25], index=[&amp;#34;omnivores&amp;#34;, &amp;#34;carnivores&amp;#34;, &amp;#34;herbivores&amp;#34;]) # Create a data frame df = pd.DataFrame([observed]).T # Add a column whose default values are the expected values df[1] = 100 # Rename columns df.columns = [&amp;#34;observed&amp;#34;, &amp;#34;expected&amp;#34;] # View the data frame df  # The degree of freedom is 3-1 = 2 # With a p-value of 0.</description>
    </item>
    
    <item>
      <title>06. Classes 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-01/06-classes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/06-classes/</guid>
      <description># Define a class class Dog():   # Utilize the Python constructor to initialize the object  def __init__(self, name, color):  self.name = name  self.color = color # Create an instance of a class dog = Dog(&amp;#39;Fido&amp;#39;, &amp;#39;brown&amp;#39;) # Print the object&amp;#39;s attributes print(dog.name) print(dog.color) </description>
    </item>
    
    <item>
      <title>06. Correlation Conundrum 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-03/06-correlation-conundrum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/06-correlation-conundrum/</guid>
      <description># Dependencies import pandas as pd import matplotlib.pyplot as plt import scipy.stats as st # Import the WDI dataset, drop missing data wdi_data = pd.read_csv(&amp;#39;../Resources/WDI_2018.csv&amp;#39;) wdi_data = wdi_data.dropna() wdi_data.head() 	# For the first example, determine which pairs of factors are correlated.  plt.scatter(wdi_data.iloc[:,1],wdi_data.iloc[:,8]) plt.xlabel(&amp;#39;Income Per Capita&amp;#39;) plt.ylabel(&amp;#39;Average Alcohol Consumed Per Person Per Year (L)&amp;#39;) plt.show()  plt.scatter(wdi_data.iloc[:,3],wdi_data.iloc[:,10]) plt.xlabel(&amp;#39;Population Median Age&amp;#39;) plt.ylabel(&amp;#39;Cell Phones Per 100 People&amp;#39;) plt.show()  plt.scatter(wdi_data.iloc[:,9],wdi_data.iloc[:,7]) plt.</description>
    </item>
    
    <item>
      <title>06. Credit Card Checker 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-03/06-credit-card-checker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-03/06-credit-card-checker/</guid>
      <description>Credit Card Checker In this activity, you will practice comparing cells to calculate the total transaction amount for different credit card brands.
Instructions   Create a VBA script that will process the credit card purchases by identifying each of the unique brands listed.
  Create a single pop-up message for each of the credit card brands listed by looping through the list.
  Bonus Add up the total value of credit card purchases for each brand, and put the information in the summary table.</description>
    </item>
    
    <item>
      <title>06. CSS 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-01/06-css/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-01/06-css/</guid>
      <description>CSS Instructions   In a new HTML file, create three ordered lists. Each list should have four items.
  The first should be a list of four cities. The entire list should have an id of &amp;ldquo;cities&amp;rdquo;.
  The second should be a list of four food entrees. Two of them should contain meat, and two of them should be vegetarian. The meat list items should have a class called &amp;ldquo;meat&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>06. Data Relationship 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-03/06-data-relationships/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/06-data-relationships/</guid>
      <description>In this activity, you will design a database model.
You are the database consultant at a new university. Your job is to design a database model for the registrar. The database will keep track of information on students, courses offered by the university, and the courses each student has taken.
Instructions   Create a students table that keeps track of the following:
  Unique ID number of each student</description>
    </item>
    
    <item>
      <title>06. Down to Input 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-01/06-down-to-input/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/06-down-to-input/</guid>
      <description>In this activity, you store inputs from the command line and run code based on those inputs.
Instructions   Create two different variables, one to take the input of your first name and one for your neighbour’s first name.
  Create two more inputs to ask how many months you and your neighbour have been coding.
  Finally, display a result with both your names and the total amount of months coding.</description>
    </item>
    
    <item>
      <title>06. Functions 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-03/06-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/06-functions/</guid>
      <description># Basic Definition def name(parameters):  # code goes here  return   # Simple Function with no parameters def show():  print(f&amp;#34;Hi!&amp;#34;)   # you use parentheses to run the code in a function show()  # Simple function with one parameter def show(message):  print(message)   # Think of the parameter `message` as a variable # You assign the string &amp;#34;Hello, World!&amp;#34; when you call the function # This is like saying `message = &amp;#34;Hello, World!</description>
    </item>
    
    <item>
      <title>06. Geoviews Maps  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-03/06-geoviews-maps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/06-geoviews-maps/</guid>
      <description></description>
    </item>
    
    <item>
      <title>06. Importing Data 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-01/06-importing-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/06-importing-data/</guid>
      <description>Files: Fauna_Vertabrate.csv
-- Drop table if exists DROP TABLE fauna_vertabrate;  -- Create new table CREATE TABLE fauna_vertabrate (  longitude DEC,  latitude DEC,  OBJECTID INT,  suburb VARCHAR,  property_name VARCHAR,  GI_class VARCHAR,  GI_type VARCHAR,  group_ VARCHAR,  family VARCHAR,  family_common_name VARCHAR,  scientific_name VARCHAR,  genus VARCHAR,  species VARCHAR,  common_name VARCHAR,  fauna_status VARCHAR );   -- View table columns and datatypes SELECT * FROM fauna_vertabrate; So far, the class has created their own tables and values manually using SQL code.</description>
    </item>
    
    <item>
      <title>06. Lotto 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-02/06-lotto/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-02/06-lotto/</guid>
      <description>The VBA Lotto For this activity, you&amp;rsquo;re in charge of finding the winners of a local lottery.
Instructions The winning tickets are:
 First place: 3957481 Second place: 5865187 Third place: 2817729  Create a script that will return those lucky winners and print them on the sheet. Make sure to do the following:
  For each winner, include the following pieces of information: first name, last name, and the winning number.</description>
    </item>
    
    <item>
      <title>06. Measuring Measures Central Tendency 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/06-measuring-measures-central-tendency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/06-measuring-measures-central-tendency/</guid>
      <description>File:
  06-Evr_MeasuringMeasures-CentralTendency/MeasuringMeasures.xlsx
  The measures of central tendency can summarize the dataset using single values, so they are a type of summary statistic. Whenever we analyze a new dataset, we should calculate all three measures of central tendency.
  Depending on the type and size of the dataset, the different measures of central tendency may or may not describe the dataset effectively.
 Therefore, we should always consider what measures of central tendency will summarize the data well before we use them in a summary table.</description>
    </item>
    
    <item>
      <title>06. Miles Per Gallon ScatterPlot  👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-02/06-miles-per-gallon-scatterplot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/06-miles-per-gallon-scatterplot/</guid>
      <description>Miles Per Gallon In this activity, you will create a scatter plot by using vehicle data, Pandas, and Matplotlib.
Instructions Create a scatter plot by using the data provided Pandas, and Matplotlib, that compares the miles per gallon of a vehicle with its horsepower. Use the following image as guidance:
References Auto MPG Dataset
 ✅ Solutions   Solutions Click Here      </description>
    </item>
    
    <item>
      <title>06. OMDb Requests  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-01/06-omdb-requests/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/06-omdb-requests/</guid>
      <description>import requests import json from config import api_key # New Dependency! Use this to pretty print the JSON # https://docs.python.org/3/library/pprint.html from pprint import pprint # Note that the ?t= is a query param for the t-itle of the # movie we want to search for. url = &amp;#34;http://www.omdbapi.com/?t=&amp;#34; api_key = &amp;#34;&amp;amp;apikey=&amp;#34; + api_key # Performing a GET request similar to the one we executed # earlier response = requests.get(url + &amp;#34;Aliens&amp;#34; + api_key) # Converting the response to JSON, and printing the result.</description>
    </item>
    
    <item>
      <title>06. Push 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-01/06-push/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-01/06-push/</guid>
      <description></description>
    </item>
    
    <item>
      <title>06. Reflecting on SQL 👩‍🎓👨‍🎓</title>
      <link>/10-advanced-sql/activities/day-02/06-reflecting-on-sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-02/06-reflecting-on-sql/</guid>
      <description>Reflecting on SQL For this activity, you’ll test your ability to reflect existing databases using SQLAlchemy and a SQLite table focused on demographic data.
Instructions   Create an engine using the demographics.sqlite database file.
  Declare a Base using automap_base(), and use this new Base class to reflect the database&amp;rsquo;s tables.
  Assign the demographics table/class to a variable called Demographics.
  Create a session, and use this session to query the Demographics table and display the first five locations.</description>
    </item>
    
    <item>
      <title>06. Roller Coaster Styling 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-01/06-rollercoaster-styling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/06-rollercoaster-styling/</guid>
      <description>Coaster Speed In this activity, you will create a line chart that graphs the speed of a roller coaster over time. You will then style the chart and add aesthetics to it.
Instructions   Create a visualization with two line plots using the following data:
  Danger Drop: [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
  RailGun: [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]</description>
    </item>
    
    <item>
      <title>06. Scrape Pandas 👩‍🏫🧑‍🏫</title>
      <link>/11-data-collection/activities/day-03/06-scrape-pandas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-03/06-scrape-pandas/</guid>
      <description>import pandas as pd  # Read in HTML tables into a DataFrame df = pd.read_html(&amp;#39;https://static.bc-edx.com/data/web/mars_facts/index.html&amp;#39;)  # Select the second table mars_df = df[1]  # Rename columns mars_df.columns=[&amp;#39;description&amp;#39;, &amp;#39;Mars&amp;#39;, &amp;#39;Earth&amp;#39;]  # Remove the first row from the DataFrame mars_df = mars_df.iloc[1:]  mars_df </description>
    </item>
    
    <item>
      <title>06. Scraping Mars News 👩‍🎓👨‍🎓</title>
      <link>/11-data-collection/activities/day-02/06-scraping-mars-news/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/11-data-collection/activities/day-02/06-scraping-mars-news/</guid>
      <description>Mars News In this activity, you&amp;rsquo;ll get additional web scraping practice by collecting data from a website based on NASA&amp;rsquo;s Mars News.
Instructions   First, open up the website in Chrome and become familiar with the layout. In this exercise, you&amp;rsquo;ll scrape the title and the summary of a news article.
  Right-click anywhere on the page, and then click Inspect. In DevTools, search for the HTML elements that you&amp;rsquo;ll use to identify the title and the summary paragraph that you want.</description>
    </item>
    
    <item>
      <title>06. Subqueries 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-02/06-subqueries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/06-subqueries/</guid>
      <description>-- First select title and id for movie EARLY HOME SELECT title, film_id FROM film WHERE title = &amp;#39;EARLY HOME&amp;#39;;  -- Using the film_id located in the previous query find it in the inventory table SELECT * FROM inventory WHERE film_id = 268;  -- Use Join to find the inventory, film and store id SELECT i.inventory_id, i.film_id, i.store_id FROM inventory i JOIN film f ON (i.film_id = f.film_id) WHERE f.</description>
    </item>
    
    <item>
      <title>06. TV Rating DataFrame 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-02/06-tv-ratings-dataframe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/06-tv-ratings-dataframe/</guid>
      <description>TV Ratings In this activity, you will create an application that reads in a list of TV shows, makes multiple requests from an API to retrieve rating information, creates a Pandas DataFrame, and then visually displays the data.
Instructions   You may use the list of TV shows provided in the starter file or create your own.
  Request information on each TV show from the TVmaze API&amp;rsquo;s Show Search endpoint</description>
    </item>
    
    <item>
      <title>06. Walrus Group  👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-03/06-walrus-group/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/06-walrus-group/</guid>
      <description>Now, open 06-Evr_WalrusGroup-Filter/Unsolved/Walrus_Group_Unsolved.xlsx activity.
  This is real data from the U.S. Geological Survey studying walruses hauled out on ice floes in Alaska.
  Select the first row of data on the sheet, then, in the “Editing” group of the “Home” tab, click the &amp;ldquo;Sort &amp;amp; Filter&amp;rdquo; button. Next, select &amp;ldquo;Filter&amp;rdquo; from the menu that pops up.
  Each column should now have an arrow button in the header cell.</description>
    </item>
    
    <item>
      <title>07. </title>
      <link>/10-advanced-sql/activities/day-03/07/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/07/</guid>
      <description></description>
    </item>
    
    <item>
      <title>07.  Column Manipulation 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-01/07-column-manipulation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/07-column-manipulation/</guid>
      <description># Import Dependencies import pandas as pd  # A gigantic DataFrame of individuals&amp;#39; names, their trainers, their weight, and their days as gym members training_df = pd.DataFrame({  &amp;#34;Name&amp;#34;:[&amp;#34;Gino Walker&amp;#34;,&amp;#34;Hiedi Wasser&amp;#34;,&amp;#34;Kerrie Wetzel&amp;#34;,&amp;#34;Elizabeth Sackett&amp;#34;,&amp;#34;Jack Mitten&amp;#34;,&amp;#34;Madalene Wayman&amp;#34;,&amp;#34;Jamee Horvath&amp;#34;,&amp;#34;Arlena Reddin&amp;#34;,&amp;#34;Tula Levan&amp;#34;,&amp;#34;Teisha Dreier&amp;#34;,&amp;#34;Leslie Carrier&amp;#34;,&amp;#34;Arlette Hartson&amp;#34;,&amp;#34;Romana Merkle&amp;#34;,&amp;#34;Heath Viviani&amp;#34;,&amp;#34;Andres Zimmer&amp;#34;,&amp;#34;Allyson Osman&amp;#34;,&amp;#34;Yadira Caggiano&amp;#34;,&amp;#34;Jeanmarie Friedrichs&amp;#34;,&amp;#34;Leann Ussery&amp;#34;,&amp;#34;Bee Mom&amp;#34;,&amp;#34;Pandora Charland&amp;#34;,&amp;#34;Karena Wooten&amp;#34;,&amp;#34;Elizabet Albanese&amp;#34;,&amp;#34;Augusta Borjas&amp;#34;,&amp;#34;Erma Yadon&amp;#34;,&amp;#34;Belia Lenser&amp;#34;,&amp;#34;Karmen Sancho&amp;#34;,&amp;#34;Edison Mannion&amp;#34;,&amp;#34;Sonja Hornsby&amp;#34;,&amp;#34;Morgan Frei&amp;#34;,&amp;#34;Florencio Murphy&amp;#34;,&amp;#34;Christoper Hertel&amp;#34;,&amp;#34;Thalia Stepney&amp;#34;,&amp;#34;Tarah Argento&amp;#34;,&amp;#34;Nicol Canfield&amp;#34;,&amp;#34;Pok Moretti&amp;#34;,&amp;#34;Barbera Stallings&amp;#34;,&amp;#34;Muoi Kelso&amp;#34;,&amp;#34;Cicely Ritz&amp;#34;,&amp;#34;Sid Demelo&amp;#34;,&amp;#34;Eura Langan&amp;#34;,&amp;#34;Vanita An&amp;#34;,&amp;#34;Frieda Fuhr&amp;#34;,&amp;#34;Ernest Fitzhenry&amp;#34;,&amp;#34;Ashlyn Tash&amp;#34;,&amp;#34;Melodi Mclendon&amp;#34;,&amp;#34;Rochell Leblanc&amp;#34;,&amp;#34;Jacqui Reasons&amp;#34;,&amp;#34;Freeda Mccroy&amp;#34;,&amp;#34;Vanna Runk&amp;#34;,&amp;#34;Florinda Milot&amp;#34;,&amp;#34;Cierra Lecompte&amp;#34;,&amp;#34;Nancey Kysar&amp;#34;,&amp;#34;Latasha Dalton&amp;#34;,&amp;#34;Charlyn Rinaldi&amp;#34;,&amp;#34;Erline Averett&amp;#34;,&amp;#34;Mariko Hillary&amp;#34;,&amp;#34;Rosalyn Trigg&amp;#34;,&amp;#34;Sherwood Brauer&amp;#34;,&amp;#34;Hortencia Olesen&amp;#34;,&amp;#34;Delana Kohut&amp;#34;,&amp;#34;Geoffrey Mcdade&amp;#34;,&amp;#34;Iona Delancey&amp;#34;,&amp;#34;Donnie Read&amp;#34;,&amp;#34;Cesar Bhatia&amp;#34;,&amp;#34;Evia Slate&amp;#34;,&amp;#34;Kaye Hugo&amp;#34;,&amp;#34;Denise Vento&amp;#34;,&amp;#34;Lang Kittle&amp;#34;,&amp;#34;Sherry Whittenberg&amp;#34;,&amp;#34;Jodi Bracero&amp;#34;,&amp;#34;Tamera Linneman&amp;#34;,&amp;#34;Katheryn Koelling&amp;#34;,&amp;#34;Tonia Shorty&amp;#34;,&amp;#34;Misha Baxley&amp;#34;,&amp;#34;Lisbeth Goering&amp;#34;,&amp;#34;Merle Ladwig&amp;#34;,&amp;#34;Tammie Omar&amp;#34;,&amp;#34;Jesusa Avilla&amp;#34;,&amp;#34;Alda Zabala&amp;#34;,&amp;#34;Junita Dogan&amp;#34;,&amp;#34;Jessia Anglin&amp;#34;,&amp;#34;Peggie Scranton&amp;#34;,&amp;#34;Dania Clodfelter&amp;#34;,&amp;#34;Janis Mccarthy&amp;#34;,&amp;#34;Edmund Galusha&amp;#34;,&amp;#34;Tonisha Posey&amp;#34;,&amp;#34;Arvilla Medley&amp;#34;,&amp;#34;Briana Barbour&amp;#34;,&amp;#34;Delfina Kiger&amp;#34;,&amp;#34;Nia Lenig&amp;#34;,&amp;#34;Ricarda Bulow&amp;#34;,&amp;#34;Odell Carson&amp;#34;,&amp;#34;Nydia Clonts&amp;#34;,&amp;#34;Andree Resendez&amp;#34;,&amp;#34;Daniela Puma&amp;#34;,&amp;#34;Sherill Paavola&amp;#34;,&amp;#34;Gilbert Bloomquist&amp;#34;,&amp;#34;Shanon Mach&amp;#34;,&amp;#34;Justin Bangert&amp;#34;,&amp;#34;Arden Hokanson&amp;#34;,&amp;#34;Evelyne Bridge&amp;#34;,&amp;#34;Hee Simek&amp;#34;,&amp;#34;Ward Deangelis&amp;#34;,&amp;#34;Jodie Childs&amp;#34;,&amp;#34;Janis Boehme&amp;#34;,&amp;#34;Beaulah Glowacki&amp;#34;,&amp;#34;Denver Stoneham&amp;#34;,&amp;#34;Tarra Vinton&amp;#34;,&amp;#34;Deborah Hummell&amp;#34;,&amp;#34;Ulysses Neil&amp;#34;,&amp;#34;Kathryn Marques&amp;#34;,&amp;#34;Rosanna Dake&amp;#34;,&amp;#34;Gavin Wheat&amp;#34;,&amp;#34;Tameka Stoke&amp;#34;,&amp;#34;Janella Clear&amp;#34;,&amp;#34;Kaye Ciriaco&amp;#34;,&amp;#34;Suk Bloxham&amp;#34;,&amp;#34;Gracia Whaley&amp;#34;,&amp;#34;Philomena Hemingway&amp;#34;,&amp;#34;Claudette Vaillancourt&amp;#34;,&amp;#34;Olevia Piche&amp;#34;,&amp;#34;Trey Chiles&amp;#34;,&amp;#34;Idalia Scardina&amp;#34;,&amp;#34;Jenine Tremble&amp;#34;,&amp;#34;Herbert Krider&amp;#34;,&amp;#34;Alycia Schrock&amp;#34;,&amp;#34;Miss Weibel&amp;#34;,&amp;#34;Pearlene Neidert&amp;#34;,&amp;#34;Kina Callender&amp;#34;,&amp;#34;Charlotte Skelley&amp;#34;,&amp;#34;Theodora Harrigan&amp;#34;,&amp;#34;Sydney Shreffler&amp;#34;,&amp;#34;Annamae Trinidad&amp;#34;,&amp;#34;Tobi Mumme&amp;#34;,&amp;#34;Rosia Elliot&amp;#34;,&amp;#34;Debbra Putt&amp;#34;,&amp;#34;Rena Delosantos&amp;#34;,&amp;#34;Genna Grennan&amp;#34;,&amp;#34;Nieves Huf&amp;#34;,&amp;#34;Berry Lugo&amp;#34;,&amp;#34;Ayana Verdugo&amp;#34;,&amp;#34;Joaquin Mazzei&amp;#34;,&amp;#34;Doris Harmon&amp;#34;,&amp;#34;Patience Poss&amp;#34;,&amp;#34;Magaret Zabel&amp;#34;,&amp;#34;Marylynn Hinojos&amp;#34;,&amp;#34;Earlene Marcantel&amp;#34;,&amp;#34;Yuki Evensen&amp;#34;,&amp;#34;Rema Gay&amp;#34;,&amp;#34;Delana Haak&amp;#34;,&amp;#34;Patricia Fetters&amp;#34;,&amp;#34;Vinnie Elrod&amp;#34;,&amp;#34;Octavia Bellew&amp;#34;,&amp;#34;Burma Revard&amp;#34;,&amp;#34;Lakenya Kato&amp;#34;,&amp;#34;Vinita Buchner&amp;#34;,&amp;#34;Sierra Margulies&amp;#34;,&amp;#34;Shae Funderburg&amp;#34;,&amp;#34;Jenae Groleau&amp;#34;,&amp;#34;Louetta Howie&amp;#34;,&amp;#34;Astrid Duffer&amp;#34;,&amp;#34;Caron Altizer&amp;#34;,&amp;#34;Kymberly Amavisca&amp;#34;,&amp;#34;Mohammad Diedrich&amp;#34;,&amp;#34;Thora Wrinkle&amp;#34;,&amp;#34;Bethel Wiemann&amp;#34;,&amp;#34;Patria Millet&amp;#34;,&amp;#34;Eldridge Burbach&amp;#34;,&amp;#34;Alyson Eddie&amp;#34;,&amp;#34;Zula Hanna&amp;#34;,&amp;#34;Devin Goodwin&amp;#34;,&amp;#34;Felipa Kirkwood&amp;#34;,&amp;#34;Kurtis Kempf&amp;#34;,&amp;#34;Kasey Lenart&amp;#34;,&amp;#34;Deena Blankenship&amp;#34;,&amp;#34;Kandra Wargo&amp;#34;,&amp;#34;Sherrie Cieslak&amp;#34;,&amp;#34;Ron Atha&amp;#34;,&amp;#34;Reggie Barreiro&amp;#34;,&amp;#34;Daria Saulter&amp;#34;,&amp;#34;Tandra Eastman&amp;#34;,&amp;#34;Donnell Lucious&amp;#34;,&amp;#34;Talisha Rosner&amp;#34;,&amp;#34;Emiko Bergh&amp;#34;,&amp;#34;Terresa Launius&amp;#34;,&amp;#34;Margy Hoobler&amp;#34;,&amp;#34;Marylou Stelling&amp;#34;,&amp;#34;Lavonne Justice&amp;#34;,&amp;#34;Kala Langstaff&amp;#34;,&amp;#34;China Truett&amp;#34;,&amp;#34;Louanne Dussault&amp;#34;,&amp;#34;Thomasena Samaniego&amp;#34;,&amp;#34;Charlesetta Tarbell&amp;#34;,&amp;#34;Fatimah Lade&amp;#34;,&amp;#34;Malisa Cantero&amp;#34;,&amp;#34;Florencia Litten&amp;#34;,&amp;#34;Francina Fraise&amp;#34;,&amp;#34;Patsy London&amp;#34;,&amp;#34;Deloris Mclaughlin&amp;#34;],  &amp;#34;Trainer&amp;#34;:[&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Calvin North&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Calvin North&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Calvin North&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Calvin North&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Calvin North&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Calvin North&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Calvin North&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Bettyann Savory&amp;#39;,&amp;#39;Barton Stecklein&amp;#39;,&amp;#39;Harland Coolidge&amp;#39;,&amp;#39;Junie Ritenour&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Pa Dargan&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Brittani Brin&amp;#39;,&amp;#39;Blanch Victoria&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Gordon Perrine&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Mariah Barberio&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Aldo Byler&amp;#39;,&amp;#39;Williams Camire&amp;#39;,&amp;#39;Coleman Dunmire&amp;#39;,&amp;#39;Phyliss Houk&amp;#39;],  &amp;#34;Weight&amp;#34;:[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],  &amp;#34;Membership(Days)&amp;#34;:[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13] }) training_df.</description>
    </item>
    
    <item>
      <title>07.  Conditionals 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-01/07-conditionals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/07-conditionals/</guid>
      <description>x = 1 y = 10  # Checks if one value is equal to another if x == 1:  print(&amp;#34;x is equal to 1&amp;#34;)  # Checks if one value is NOT equal to another if y != 1:  print(&amp;#34;y is not equal to 1&amp;#34;)  # Checks if one value is less than another if x &amp;lt; y:  print(&amp;#34;x is less than y&amp;#34;)  # Checks if one value is greater than another if y &amp;gt; x:  print(&amp;#34;y is greater than x&amp;#34;)  # Checks if a value is greater than or equal to another if x &amp;gt;= 1:  print(&amp;#34;x is greater than or equal to 1&amp;#34;)  # Checks for two conditions to be met using &amp;#34;and&amp;#34; if x == 1 and y == 10:  print(&amp;#34;Both values returned true&amp;#34;)  # Checks if either of two conditions is met if x &amp;lt; 45 or y &amp;lt; 5:  print(&amp;#34;One or more of the statements were true&amp;#34;)  # Nested if statements if x &amp;lt; 10:  if y &amp;lt; 5:  print(&amp;#34;x is less than 10 and y is less than 5&amp;#34;)  elif y == 5:  print(&amp;#34;x is less than 10 and y is equal to 5&amp;#34;)  else:  print(&amp;#34;x is less than 10 and y is greater than 5&amp;#34;) </description>
    </item>
    
    <item>
      <title>07.  Intro to bug fixing 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-03/07-intro-to-bug-fixing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-03/07-intro-to-bug-fixing/</guid>
      <description># Import dependencies import pandas as pd # Reference to CSV and reading CSV into Pandas DataFrame csv_path = &amp;#34;Resources/veterans.csv&amp;#34; veterans_df = pd.read_csv(csv_path) veterans_df.head()  veterans_df.columns  # Converting the &amp;#34;Percentage&amp;#34; column to floats veterans_df[&amp;#34;Percentage&amp;#34;] = veterans_df[&amp;#34;Percentage&amp;#34;].str.replace(&amp;#34;%&amp;#34;, &amp;#34;&amp;#34;).astype  # Finding the average percentage of veterans living within 75 miles of a cemetery veterans_df[&amp;#34;Percentage&amp;#34;].mean() </description>
    </item>
    
    <item>
      <title>07.  Nested For Loop  👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-02/07-nested-for-loops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-02/07-nested-for-loops/</guid>
      <description>&amp;#39; Nested For Loop  Sub ClassScanner()   Dim TargetStudent As String   &amp;#39; Loop through the rows  For i = 1 To 3   &amp;#39; Loop through the columns  For j = 1 To 5   &amp;#39; Print the Student Name  MsgBox (&amp;#34;Row: &amp;#34; &amp;amp; i &amp;amp; &amp;#34; Column: &amp;#34; &amp;amp; j &amp;amp; &amp;#34; | &amp;#34; &amp;amp; Cells(i, j).Value)   Next j   Next i  End Sub </description>
    </item>
    
    <item>
      <title>07. Airport Map 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-03/07-airport-map/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/07-airport-map/</guid>
      <description>Australian Airports Map In this activity, you will create a map based on Australian airports information that you generated before using the Geoapify API.
Instructions   Load airports&amp;rsquo; data into a Pandas DataFrame.
  Create a simple map using GeoViews by adding a point per airport and setting a fixed size at your convenience.
  Use GeoViews to create a custom map by setting values for color, size, and a title different than OSM.</description>
    </item>
    
    <item>
      <title>07. Barcharts 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-01/07-barcharts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/07-barcharts/</guid>
      <description>%matplotlib notebook import matplotlib.pyplot as plt import numpy as np  # Create an array that contains the number of users each language has users = [13000, 26000, 52000, 30000, 9000] x_axis = np.arange(len(users))  # Tell matplotlib that we will be making a bar chart # Users is our y axis and x_axis is, of course, our x axis # We apply align=&amp;#34;edge&amp;#34; to ensure our bars line up with our tick marks plt.</description>
    </item>
    
    <item>
      <title>07. Census Group By 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-02/07-census-groupby/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/07-census-groupby/</guid>
      <description>Exploring Census Data In this activity, you will revisit the U.S. Census data and create DataFrames with calculated totals and averages for each state by year.
Instructions   Read in the census CSV file with Pandas.
  Create two new DataFrames, one to find totals and another to find averages. DataFrames should include:
  Totals for population, employed civilians, unemployed civilians, people in the military, and poverty count.</description>
    </item>
    
    <item>
      <title>07. Census Part 1 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-03/07-census-pt1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-03/07-census-pt1/</guid>
      <description>U.S. Census, Part 1 In this first part of the activity, you will create a VBA script that loops through the sheets in the workbook and formats each one to be more readable.
Instructions   Extract the number before the phrase &amp;ldquo;_census_data&amp;rdquo; to figure out the year.
  Add the year to the first column of each spreadsheet.
  Split the &amp;ldquo;Place&amp;rdquo; column into &amp;ldquo;County&amp;rdquo; and &amp;ldquo;State&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>07. Chi Square 👩‍🏫🧑‍🏫</title>
      <link>/07-project-1-part-1/activities/day-03/07-chi-square/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/07-project-1-part-1/activities/day-03/07-chi-square/</guid>
      <description></description>
    </item>
    
    <item>
      <title>07. Correlation_Conquerors 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-03/07-correlation-conquerors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/07-correlation-conquerors/</guid>
      <description>✅ Solutions   Solutions Click Here      </description>
    </item>
    
    <item>
      <title>07. ERD 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-03/07-erd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/07-erd/</guid>
      <description>Conceptual Schema # Conceptual (without relationships) Employee - Zipcode - Employee_Email - Owners - Estates - Estate_Type - Agents - Regions - Agent_Region_Junction - # Conceptual (with relationships) Employee rel Zipcode - Zipcode - Employee_Email rel Employee - Owners - Estates rel Owners rel Estate_Type rel Zipcode - Estate_Type - Agents - Regions - Agent_Region_Junction rel Agents rel Regions - Logical # Logical Employee - Employee_ID PK Name Age Address Zipcode FK - Zipcode.</description>
    </item>
    
    <item>
      <title>07. Explore OMDb API 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-01/07-explore-omdb-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/07-explore-omdb-api/</guid>
      <description>OMDb API In this activity, you’ll review the OMDb API documentation, and you’ll practice using the API.
Instructions Read the OMDb documentation, and make a few API calls to get some information about your favorite movie.
 ✅ Solutions   Solutions Click Here      </description>
    </item>
    
    <item>
      <title>07. Filter Home Sales 👩‍🎓👨‍🎓 </title>
      <link>/01-excel/activities/day-03/07-filter-home-sales/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/07-filter-home-sales/</guid>
      <description>Filtering Home Sales Now that you can apply filters to a spreadsheet and create charts based on filtered datasets, you’ll work in pairs to create charts that compare the sales of homes in St. Louis, MO. Specifically, you&amp;rsquo;ll create a filtered chart that visualizes increases in waterfront properties over time in the St. Louis Area.
Instructions   Use the St. Louis Home Sales Dataset provided.
  Examine the data and check out the available columns.</description>
    </item>
    
    <item>
      <title>07. Formatting 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/07-formatting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/07-formatting/</guid>
      <description>NumberType File:
  07-Ins_Formatting/NumberTypes.xlsx
  Excel can style the numeric data of a spreadsheet so that it looks a certain way. This can be done by selecting a cell or a range of numeric data, clicking on the &amp;ldquo;Number&amp;rdquo; group, and then selecting any of the available numeric styles.
  It is important to note that we are only altering the look or appearance of the number. In the following image, the data itself is the same as it was before we applied the styling, but we’ve formatted the original value as a currency:</description>
    </item>
    
    <item>
      <title>07. Functions 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-03/07-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/07-functions/</guid>
      <description>In this activity, you will write a function to compute the arithmetic mean (average) for a list of numbers.
Instructions   Write a function called average that accepts a list of numbers.
 The function average should return the arithmetic mean (average) for a list of numbers.    Test your function by calling it with different values and printing the results.
   ✅ Solutions   Solutions Click Here   # Write a function that returns the arithmetic average for a list of numbers def average(numbers):  length = len(numbers)  total = 0.</description>
    </item>
    
    <item>
      <title>07. Inspection 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-02/07-inspection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-02/07-inspection/</guid>
      <description># Import SQLAlchemy `automap` and other dependencies import sqlalchemy from sqlalchemy.ext.automap import automap_base from sqlalchemy.orm import Session from sqlalchemy import create_engine, inspect # Create the connection engine engine = create_engine(&amp;#34;sqlite:///./resources/dow.sqlite&amp;#34;) # Create the inspector and connect it to the engine inspector = inspect(engine) # Collect the names of tables within the database inspector.get_table_names()  # Using the inspector to print the column names within the &amp;#39;dow&amp;#39; table and its types columns = inspector.</description>
    </item>
    
    <item>
      <title>07. Module Playground   👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-02/07-module-playground/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/07-module-playground/</guid>
      <description>In this activity, you will have the opportunity to explore and play around with some Python modules.
Instructions There are tons of built-in modules for Python. Review some of Python&amp;rsquo;s modules and play around with them. Use the following link:
👉 List of Built-In Python Modules
 </description>
    </item>
    
    <item>
      <title>07. Pandas Multi Line 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-02/07-pandas-multi-line/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/07-pandas-multi-line/</guid>
      <description># Dependencies import matplotlib.pyplot as plt import numpy as np import pandas as pd # Read CSV unemployed_data_one = pd.read_csv(&amp;#34;../Resources/unemployment_2010-2015.csv&amp;#34;) unemployed_data_two = pd.read_csv(&amp;#34;../Resources/unemployment_2016-2020.csv&amp;#34;)  # Merge our two data frames together combined_unemployed_data = pd.merge(unemployed_data_one, unemployed_data_two, on=&amp;#34;Country Name&amp;#34;) combined_unemployed_data.head()  # Delete the duplicate &amp;#39;Country Code&amp;#39; column and rename the first one back to &amp;#39;Country Code&amp;#39; del combined_unemployed_data[&amp;#39;Country Code_y&amp;#39;] combined_unemployed_data = combined_unemployed_data.rename(columns={&amp;#34;Country Code_x&amp;#34;:&amp;#34;Country Code&amp;#34;}) combined_unemployed_data.head() 	# Set the &amp;#39;Country Code&amp;#39; to be our index for easy referencing of rows combined_unemployed_data = combined_unemployed_data.</description>
    </item>
    
    <item>
      <title>07. Subqueries 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-02/07-subqueries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/07-subqueries/</guid>
      <description>Subqueries In this activity, you will practice creating subqueries.
Instructions   List the names and ID numbers of cities that are in the following list: Qalyub, Qinhuangdao, Qomsheh, Quilmes.
  Display the districts in the above list of cities.
Hint: Use the address and city tables.
  Bonus Using subqueries, find the first and last names of customers who reside in cities that begin with the letter Q.</description>
    </item>
    
    <item>
      <title>07. Surfer Class 👩‍🎓👨‍🎓</title>
      <link>/10-advanced-sql/activities/day-01/07-surfer-class/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/07-surfer-class/</guid>
      <description>In this activity, you will create your own classes in Python.
Instructions   Create a class, Surfer, and initialize it with name, hometown, and rank-instance variables.
  Create an instance of a surfer.
  Then, print the name, hometown, and rank of your surfer object.
  Bonus   Create a while loop that will allow you to continuously create new instances of surfers using input().</description>
    </item>
    
    <item>
      <title>07. Variables 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-01/07-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/07-variables/</guid>
      <description>Sub Variables():   &amp;#39; Basic String Variable  &amp;#39; ----------------------------------------  Dim name As String  name = &amp;#34;Gandalf&amp;#34;   MsgBox (name)   &amp;#39; Basic String Concatenation (Combination)  &amp;#39; ----------------------------------------  Dim title As String  title = &amp;#34;The Great&amp;#34;   Dim fullname As String  fullname = name + &amp;#34; &amp;#34; + title   MsgBox (fullname)   &amp;#39; Basic Integer, Double, Long Variables  &amp;#39; ----------------------------------------  Dim age1 As Integer  Dim age2 As Integer  age1 = 5  age2 = 10   Dim price As Double  Dim tax As Double  price = 19.</description>
    </item>
    
    <item>
      <title>07. Weather Stats 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-02/07-weather-stats/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/07-weather-stats/</guid>
      <description>Weather Statistics In this activity, you will perform a linear regression on weather data from select cities in the Northern Hemisphere, and you will use the results to predict the temperature in Florence, Italy.
Instructions   Using the starter file as a guide, complete the following steps:
  Create a scatter plot of Temperature vs. Latitude.
  Perform linear regression.
  Create a line equation for the regression.</description>
    </item>
    
    <item>
      <title>07. Hide and Seek 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-01/07-hide-and-seek/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/07-hide-and-seek/</guid>
      <description>Hide and Seek In this activity, you will create a new table and import data from a CSV file. To learn more about this dataset, you may review the reference at the end of this document.
Instructions   Open the soft-attributes.csv CSV file from the Resources folder to analyze the data.
  Using the column headers and data types from the CSV file, write the table schema to create a new table in the Miscellaneous_DB database called movie_words_comparison.</description>
    </item>
    
    <item>
      <title>08. </title>
      <link>/10-advanced-sql/activities/day-03/08/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/08/</guid>
      <description></description>
    </item>
    
    <item>
      <title>08.  Conditionals Conundrum 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-01/08-conditionals-conundrum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/08-conditionals-conundrum/</guid>
      <description>In this activity, you’ll review prewritten conditionals and predict the lines that will be printed to the console.
Instructions   Go through the conditionals in the provided code, and predict the lines that will be printed to the console.
  Do not run the code at first. Try to follow the thought process for each chunk of code and then make a guess. Only after coming up with a guess for each section should you run the application.</description>
    </item>
    
    <item>
      <title>08.  Hey Arnold DataFrame 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-01/08-hey-arnold-dataframe-formatting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/08-hey-arnold-dataframe-formatting/</guid>
      <description>In this activity, you will take a premade DataFrame of “Hey Arnold!” characters and reorganize it so that it is easier to understand.
Instructions Use Pandas to create a DataFrame with the following columns and values:
  “Character_in_show”: Arnold, Gerald, Helga, Phoebe, Harold, Eugene
  “color_of_hair”: blonde, black, blonde, black, unknown, red
  “Height”: average, tallish, tallish, short, tall, short
  “Football_Shaped_Head”: True, False, False, False, False, False</description>
    </item>
    
    <item>
      <title>08.  Sorting 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-02/08-sorting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/08-sorting/</guid>
      <description># Import Dependencies import pandas as pd csv_path = &amp;#34;Resources/VT_tax_statistics.csv&amp;#34; taxes_df = pd.read_csv(csv_path, encoding=&amp;#34;UTF-8&amp;#34;) taxes_df.head()  # Sorting the DataFrame based on &amp;#34;Meals&amp;#34; column # Will sort from lowest to highest if no other parameter is passed meals_taxes_df = taxes_df.sort_values(&amp;#34;Meals&amp;#34;) meals_taxes_df.head()  # To sort from highest to lowest, ascending=False must be passed in meals_taxes_df = taxes_df.sort_values(&amp;#34;Meals&amp;#34;, ascending=False) meals_taxes_df.head()  # It is possible to sort based upon multiple columns meals_and_rent_count_df = taxes_df.</description>
    </item>
    
    <item>
      <title>08. Bug Fixing Bonanza  👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-03/08-bug-fixing-bonanza/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-03/08-bug-fixing-bonanza/</guid>
      <description>✅ Solutions   Solutions Click Here    import pandas as pd # Create a reference to the CSV and import it into a Pandas DataFrame csv_path = &amp;#34;Resources/Bedbug_Reporting.csv&amp;#34; bugs_df = pd.read_csv(csv_path) bugs_df.head()  bugs_df.columns  # Remove the extra space from &amp;#34;Re-infested Dwelling Unit Count&amp;#34; column bugs_df = bugs_df.rename(  columns={&amp;#34;Re-infested Dwelling Unit Count&amp;#34;: &amp;#34;Re-infested Dwelling Unit Count&amp;#34;}) # Columns we&amp;#39;re interested in: &amp;#39;Building ID&amp;#39;, &amp;#39;Borough&amp;#39;, &amp;#39;Postcode&amp;#39;, &amp;#39;# of Dwelling Units&amp;#39;, # &amp;#39;Infested Dwelling Unit Count&amp;#39;, &amp;#39;Eradicated Unit Count&amp;#39;, # &amp;#39;Re-infested Dwelling Unit Count&amp;#39;, &amp;#39;Filing Date&amp;#39;, &amp;#39;Latitude&amp;#39;, &amp;#39;Longitude&amp;#39; bugs_df = bugs_df[[&amp;#39;Building ID&amp;#39;, &amp;#39;Borough&amp;#39;, &amp;#39;Postcode&amp;#39;, &amp;#39;# of Dwelling Units&amp;#39;,  &amp;#39;Infested Dwelling Unit Count&amp;#39;, &amp;#39;Eradicated Unit Count&amp;#39;,  &amp;#39;Re-infested Dwelling Unit Count&amp;#39;, &amp;#39;Filing Date&amp;#39;,  &amp;#39;Latitude&amp;#39;, &amp;#39;Longitude&amp;#39;]] bugs_df.</description>
    </item>
    
    <item>
      <title>08. Calculator 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-01/08-calculator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/08-calculator/</guid>
      <description>Calculator Now, you will have the opportunity to use data in a spreadsheet to create variables and perform a simple calculation.
Instructions   Using the spreadsheet and unsolved VBS code as a starter, complete the script so that Price, Tax, Quantity, and Total are stored in variables.
  Then, assign these variables the value of their associated cell in the spreadsheet.
  Once complete, your code should set the Total value in the spreadsheet.</description>
    </item>
    
    <item>
      <title>08. Census  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-03/08-census/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/08-census/</guid>
      <description></description>
    </item>
    
    <item>
      <title>08. Census Part 2 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-03/08-census-pt2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-03/08-census-pt2/</guid>
      <description>U.S. Census, Part 2 In this second part of this activity, you will combine all the worksheets into one massive table in a new sheet.
Instructions   Loop through every worksheet, and select the year contents.
  Copy the year contents, and paste them into the Combined_Data tab.
  References Data Source: U.S. Census API - ACS 5-Year Estimates 2016-2019
—</description>
    </item>
    
    <item>
      <title>08. Classes With Methods 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-01/08-classes-with-methods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/08-classes-with-methods/</guid>
      <description># Define the Film class class Film():   # A required function to initialize the class object  def __init__(self, name, length, release_year, language):  self.name = name  self.length = length  self.release_year = release_year  self.language = language # An object belonging to the Film class star_wars = Film(&amp;#34;Star Wars&amp;#34;, 121, 1977, &amp;#34;English&amp;#34;)   # Define the Expert class class Expert():   # A required function to initialize the class object  def __init__(self, name):  self.</description>
    </item>
    
    <item>
      <title>08. Create Views 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-02/08-create-views/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/08-create-views/</guid>
      <description>SELECT s.store_id, SUM(amount) AS Gross FROM payment AS p  JOIN rental AS r  ON (p.rental_id = r.rental_id)  JOIN inventory AS i  ON (i.inventory_id = r.inventory_id)  JOIN store AS s  ON (s.store_id = i.store_id)  GROUP BY s.store_id;   -- Create view from query CREATE VIEW total_sales AS SELECT s.store_id, SUM(amount) AS Gross FROM payment AS p JOIN rental AS r ON (p.rental_id = r.</description>
    </item>
    
    <item>
      <title>08. Cypto Kennel 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-02/08-cryptokennel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-02/08-cryptokennel/</guid>
      <description>Crypto Kennel The spreadsheet you&amp;rsquo;ll be working with in this activity is full of animal inspired cryptocurrency! In place of numerical data, when you open your file you&amp;rsquo;ll be greeted by cells filled with the words &amp;ldquo;Shiba Inu&amp;rdquo;, &amp;ldquo;Dogecoin&amp;rdquo;, or &amp;ldquo;Cat Token&amp;rdquo;, however your crypto kennel is for canines only! Instead of manually removing the unwanted feline crypto, you&amp;rsquo;ll use VBA to do the work for you.
Instructions   Create a VBA script to handle the over-abundance of the Cat Token currency in your spreadhseet&amp;rsquo;s &amp;ldquo;crypto kennel&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>08. Designing ERD 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-03/08-designing-erd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/08-designing-erd/</guid>
      <description>Designing an ERD, Part 1 In this activity, you will work on the following scenario with a partner:
You are meeting with a gym owner who wants to organize his data in a database. This will require creating a conceptual ERD for the owner.
Instructions   Create a conceptual ERD by determining the entities and their attributes that will exist in the database. Be sure to include the following: trainers, members, and gym as well as one more entity that you think is necessary.</description>
    </item>
    
    <item>
      <title>08. Exception Handling  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-02/08-exception-handling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/08-exception-handling/</guid>
      <description>students = {  # Name : Age  &amp;#34;James&amp;#34;: 27,  &amp;#34;Sarah&amp;#34;: 19,  &amp;#34;Jocelyn&amp;#34;: 28 }  print(students[&amp;#34;Mary&amp;#34;])  print(&amp;#34;This line will never print.&amp;#34;) students = {  # Name : Age  &amp;#34;James&amp;#34;: 27,  &amp;#34;Sarah&amp;#34;: 19,  &amp;#34;Jocelyn&amp;#34;: 28 }  # Try to access key that doesn&amp;#39;t exist try:  students[&amp;#34;Mary&amp;#34;] except KeyError:  print(&amp;#34;Oops, that key doesn&amp;#39;t exist.&amp;#34;)  # &amp;#34;Catching&amp;#34; the error lets the rest of our code execute print(&amp;#34;.</description>
    </item>
    
    <item>
      <title>08. Fits and Regression 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-03/08-fits-and-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/08-fits-and-regression/</guid>
      <description># Import dependencies from matplotlib import pyplot as plt from scipy.stats import linregress import numpy as np from sklearn import datasets import pandas as pd  # Read in the California housing dataset california_dataset = datasets.fetch_california_housing() housing_data = pd.DataFrame(data=california_dataset.data,columns=california_dataset.feature_names) housing_data[&amp;#39;MEDV&amp;#39;] = california_dataset.target # Reduce the dataset to remove AveRooms outliers housing_data_reduced = pd.DataFrame(housing_data.loc[housing_data[&amp;#39;AveRooms&amp;#39;]&amp;lt;10,:])  # Reduce the dataset to the San Diego Area (based on approx latitude &amp;amp; longitude area) san_diego_housing = pd.</description>
    </item>
    
    <item>
      <title>08. Graduation  👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-03/08-graduation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/08-graduation/</guid>
      <description>Graduating Functions In this activity, you will create a function that searches a list of students and graduates by state to determine state graduation rates for public, private nonprofit, and private for-profit institutions.
Instructions   Analyze the code and CSV provided, looking specifically for what needs to still be added to the application.
  Using the starter code provided, create a function called print_percentages which takes in a parameter called state_data and does the following:</description>
    </item>
    
    <item>
      <title>08. Movie Questions 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-01/08-movie-questions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/08-movie-questions/</guid>
      <description>Movie Questions In this activity, you will test your skills with the OMDb API by collecting data to answer a series of questions.
Instructions Use the OMDb API to retrieve and print answers to the following questions:
  Who was the director of the movie Aliens?
  What was the movie Gladiator rated?
  What year was 50 First Dates released?
  Who wrote Moana?
  What was the plot of the movie Sing?</description>
    </item>
    
    <item>
      <title>08. PyBars  👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-01/08-pybars/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/08-pybars/</guid>
      <description>Cars Bar Chart In this activity, you will create a bar chart that visualizes the commuting cars per 1,000 population aged 16 and over within major U.S. cities.
Instructions create a bar chart that matches the following image:
  Title: Density of Commuting Cars in Cities
  x-axis label: Cities
  x-tick labels: San Francisco, Omaha, New Orleans, Cincinnati, Pittsburgh
  y-axis label: Commuting Cars Per 1,000 Population Age 16+</description>
    </item>
    
    <item>
      <title>08. Read CSV 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-02/08-read-csv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/08-read-csv/</guid>
      <description># First we&amp;#39;ll import the os module # This will allow us to create file paths across operating systems import os  # Module for reading CSV files import csv   csvpath = os.path.join(&amp;#39;.&amp;#39;, &amp;#39;Resources&amp;#39;, &amp;#39;contacts.csv&amp;#39;)  # Method 1: Plain Reading of CSV files with open(csvpath, &amp;#39;r&amp;#39;) as file_handler:  lines = file_handler.read()  print(lines)  print(type(lines))  # Method 2: Improved Reading using CSV module  with open(csvpath) as csvfile:   # CSV reader specifies delimiter and variable that holds contents  csvreader = csv.</description>
    </item>
    
    <item>
      <title>08. Salary Explore 👩‍🎓👨‍🎓</title>
      <link>/10-advanced-sql/activities/day-02/08-salary-explore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-02/08-salary-explore/</guid>
      <description>Salary Exploration For this activity, you will create an inspector and search through a SQLite database of San Francisco salaries.
Instructions Using the attached SQLite file, use an inspector to collect the following information:
  The names of all of the tables within the database
  The column names and data types for the salaries table
  References DataSF. (2022). OpenData. Employee Compensation, City Management and Ethics. Data provided by SF Controller&amp;rsquo;s Office.</description>
    </item>
    
    <item>
      <title>08. Skip 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/08-skip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/08-skip/</guid>
      <description>No Activity for Number 8 🤷 </description>
    </item>
    
    <item>
      <title>08. Traveling Companions  Part 1  👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-02/08-traveling-companion-part-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/08-traveling-companion-part-1/</guid>
      <description>Traveling Companions, Part 1 This is Part 1 of a three-part mini-project.
In this first part of the activity, you will take three separate CSVs that were gathered from Tourism Malaysia, merge them together, and then create charts to visualize a comparison of travelers to Malaysia from different countries of origin over three years.
Instructions   Check the comments in each cell of this Jupyter Notebook file for activity instructions.</description>
    </item>
    
    <item>
      <title>08. Variance SDZ Score Review 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-03/08-variance-sd-zscore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/08-variance-sd-zscore/</guid>
      <description>We will discuss the summary statistics that are used to describe the variability of a dataset.
  variance, standard deviation, and z-score are the summary statistics used to describe the variability in data.
  variance is an overall description of how far values in the dataset are from the mean. In other words, variance describes how much variation exists within the data.
  the equation for variance with the as captured in the following image:</description>
    </item>
    
    <item>
      <title>08. CRUD 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-01/08-crud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/08-crud/</guid>
      <description>Using CRUD: Create, Read, Update, and Delete In this activity, you will use CRUD operations (Create, Read, Update, Delete) on the provided data.
Instructions   Create a new database named Malaysia in pgAdmin.
  Create two new tables in the Malaysia database by copying the code provided in schema.sql into a new query window in pgAdmin.
  Using the Import/Export tool, import the data from mys_road_accidents.csv into the road_accidents table, and then import the data from mys_accidents_by_state.</description>
    </item>
    
    <item>
      <title>09. </title>
      <link>/10-advanced-sql/activities/day-03/09/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/09/</guid>
      <description></description>
    </item>
    
    <item>
      <title>09.  List 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-01/09-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/09-list/</guid>
      <description># Create a variable and set it as an List myList = [&amp;#34;Kirra&amp;#34;, 25, &amp;#34;Ahmed&amp;#34;, 80] print(myList)   # Adds an element onto the end of a List myList.append(&amp;#34;Matt&amp;#34;) print(myList)  # Returns the index of the first object with a matching value print(myList.index(&amp;#34;Matt&amp;#34;))   # Changes a specified element within an List at the given index myList[3] = 85 print(myList)   # Returns the length of the List print(len(myList))  # Removes a specified object from an List myList.</description>
    </item>
    
    <item>
      <title>09.  Reading Writing CSV 👩‍🏫🧑‍🏫</title>
      <link>/04-pandas/activities/day-01/09-reading-writing-csv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/09-reading-writing-csv/</guid>
      <description># Dependencies import pandas as pd  # Store filepath in a variable file_one = &amp;#34;./Resources/DataOne.csv&amp;#34;  # Read our Data file with the pandas library # Not every CSV requires an encoding, but be aware this can come up file_one_df = pd.read_csv(file_one, encoding=&amp;#34;ISO-8859-1&amp;#34;)  # Show just the header file_one_df.head()  # Show a single column file_one_df[&amp;#34;full_name&amp;#34;].head()  # Show mulitple specific columns--note the extra brackets file_one_df[[&amp;#34;full_name&amp;#34;, &amp;#34;email&amp;#34;]].head()  # Head does not change the DataFrame--it only displays it file_one_df.</description>
    </item>
    
    <item>
      <title>09.  Search for the worst 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-02/09-search-for-the-worst/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-02/09-search-for-the-worst/</guid>
      <description>Search For The Worst In this activity, you will take a dataset on San Francisco Airport&amp;rsquo;s utility consumption and determine which day in the dataset had the worst consumption for each utility.
Instructions   Read in the CSV file provided, and print it to the screen.
  Print out a list of all the values within the &amp;ldquo;Utility&amp;rdquo; column.
  Select a value from this list, and create a new DataFrame that only includes that utility.</description>
    </item>
    
    <item>
      <title>09. Arrays 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-01/09-arrays/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/09-arrays/</guid>
      <description>Sub SimpleArrays():   &amp;#39; Basic Array Example  &amp;#39; ------------------------------------------  &amp;#39; Create the Ingredients Array  Dim Ingredients(5) as String   &amp;#39; Add Ingredients to the Array  Ingredients(0) = &amp;#34;Chocolate Bar&amp;#34;  Ingredients(1) = &amp;#34;Peanut Butter&amp;#34;  Ingredients(2) = &amp;#34;Jelly&amp;#34;  Ingredients(3) = &amp;#34;Macaroni&amp;#34;  Ingredients(4) = &amp;#34;Potato Salad&amp;#34;  Ingredients(5) = &amp;#34;Dragonfruit&amp;#34;   &amp;#39; Retrieve specific elements of the array  MsgBox(Ingredients(4))  MsgBox(Ingredients(0))  End Sub </description>
    </item>
    
    <item>
      <title>09. Banking Deserts  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-03/09-banking-deserts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-03/09-banking-deserts/</guid>
      <description>Banking Deserts In this activity, your task is to understand if there is a relationship between poverty, age, population, and the number of banks in a given area. To help, we’ve provided you with Census data for every U.S. zip code. You will also visualize this data using GeoViews.
Instructions   Retrieve data from the U.S. Census using the Census Python library and the preconfigured labels.
  Load the zip_bank_data.</description>
    </item>
    
    <item>
      <title>09. ERD Part 2 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-03/09-erd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/09-erd/</guid>
      <description>Designing an ERD, Part 2 In this activity, you and your partner will continue designing an entity relationship diagram for the gym by transitioning your logical ERD (created in the previous activity) to a physical ERD.
Instructions   Using the starter code provided, return to Quick Database Diagrams and transition your logical ERD to a physical ERD by creating the relationships between tables.
  When you are satisfied with your ERD, write a corresponding schema file containing your CREATE TABLE statements</description>
    </item>
    
    <item>
      <title>09. Fits and Regression 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-03/09-fits-and-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-03/09-fits-and-regression/</guid>
      <description>Fits and Regression This activity is an opportunity to use SciPy to fit data and Matplotlib to display the fit.
Instructions   Generate a scatter plot with Matplotlib using the year as the independent (x) variable and the number of petrol-electric cars as the dependent (y) variable.
  Use stats.linregress to perform a linear regression with the year as the independent variable (x) and the number of petrol-electric cars as the dependent variable (y).</description>
    </item>
    
    <item>
      <title>09. Git 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-03/09-adding-more-to-the-repo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-03/09-adding-more-to-the-repo/</guid>
      <description>You only added files using the GitHub website, which works well enough when just dealing with one or two files. What happens when we need to quickly add multiple files?
 The command line comes to the rescue!    Creating a repo and adding files with Terminal/Git Bash.
  First, create a new repo.
  From the repo page, click the green box in the top-right labeled &amp;ldquo;Clone or download&amp;rdquo;, select &amp;ldquo;Use SSH&amp;rdquo;, and copy the link to the clipboard, as captured in the following GIF:</description>
    </item>
    
    <item>
      <title>09. Iterative Requests 👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-01/09-iterative-requests/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/09-iterative-requests/</guid>
      <description># Dependencies import random import json import requests  # Let&amp;#39;s get the JSON for 100 posts sequentially. url = &amp;#34;http://jsonplaceholder.typicode.com/posts/&amp;#34; # Create an empty list to store the responses response_json = [] # Create random indices representing # a user&amp;#39;s choice of posts indices = random.sample(list(range(1, 100)), 10) indices  # Make a request for each of the indices for x in range(len(indices)):  print(f&amp;#34;Making request number: {x}for ID: {indices[x]}&amp;#34;)   # Get one of the posts  post_response = requests.</description>
    </item>
    
    <item>
      <title>09. Joins 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-01/09-joins/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/09-joins/</guid>
      <description>-- Drop table if exists DROP TABLE names;  -- Create the names table CREATE TABLE Names ( 	i INT PRIMARY KEY, 	dep_id INT, 	line INT, 	name VARCHAR, 	status VARCHAR, 	inserted_by VARCHAR, 	insert_date DATE, 	updated_by VARCHAR, 	update_date DATE );  -- Check data import SELECT * FROM names;  -- Create the commodity table CREATE TABLE commodity ( 	i INT PRIMARY KEY, 	dep_id INT, 	line INT, 	commod VARCHAR, 	code VARCHAR, 	commod_tp VARCHAR, 	commod_group VARCHAR, 	import VARCHAR, 	inserted_by VARCHAR, 	insert_date DATE, 	updated_by VARCHAR, 	update_date DATE );  -- Check data import SELECT * FROM commodity;  -- Perform an INNER JOIN on the two tables SELECT names.</description>
    </item>
    
    <item>
      <title>09. Making Exceptions 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-02/09-making-exceptions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/09-making-exceptions/</guid>
      <description>Making Exceptions In this activity, you will create an application that uses try and except to resolve a number of errors.
Instructions   Without removing any of the lines from the provided starter code, create try-except blocks that will allow the application to run without terminating.
  Each except block should handle the specific error that will occur.
  Add a print statement under the except block to log the error.</description>
    </item>
    
    <item>
      <title>09. Pie Charts 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-01/09-piecharts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/09-piecharts/</guid>
      <description>%matplotlib notebook # Import our dependencies  import matplotlib.pyplot as plt import numpy as np # Labels for the sections of our pie chart labels = [&amp;#34;Humans&amp;#34;, &amp;#34;Smurfs&amp;#34;, &amp;#34;Hobbits&amp;#34;, &amp;#34;Ninjas&amp;#34;]  # The values of each section of the pie chart sizes = [220, 95, 80, 100]  # The colors of each section of the pie chart colors = [&amp;#34;red&amp;#34;, &amp;#34;orange&amp;#34;, &amp;#34;lightcoral&amp;#34;, &amp;#34;lightskyblue&amp;#34;]  # Tells matplotlib to separate the &amp;#34;Humans&amp;#34; section from the others explode = (0.</description>
    </item>
    
    <item>
      <title>09. Pivot Tables 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/09-pivot-tables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/09-pivot-tables/</guid>
      <description>File 09-Ins_PivotTables/PivotTables_Solved.xlsx for this activity.
  Powerful tool in the Excel arsenal is the pivot table, which allows users to extract summary data from large, detailed, and consistent datasets.
  Explain that pivot tables summarize data using functions like SUM, COUNT, and AVERAGE on subsets of the data. These subsets can be as general or as specific as we like.
  Caution pivot tables are not designed for deeper analysis.</description>
    </item>
    
    <item>
      <title>09. Reading Comic Book  👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-02/09-reading-comic-book/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/09-reading-comic-book/</guid>
      <description>In this activity, you will create an application that searches the provided CSV file for a specific graphic novel title and then returns the title, publisher’s name, and the year it was published.
Instructions   Prompt the user for the book title they’d like to search.
  Search through the comic_books.csv to find the user&amp;rsquo;s book.
  If the CSV contains the user&amp;rsquo;s title, then print out the title, the publisher name, and the year it was published.</description>
    </item>
    
    <item>
      <title>09. Surfer Class Extended 👩‍🎓👨‍🎓 </title>
      <link>/10-advanced-sql/activities/day-01/09-surfer-class-extended/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/09-surfer-class-extended/</guid>
      <description>In this activity, you will rework your Surfer script as you add in methods to perform specific tasks.
Instructions   Create a Surfer class that has name, hometown, rank, and wipeouts instance variables.
  Create a method called speak that prints &amp;ldquo;Hang loose, bruh!&amp;rdquo;
  Create a method called biography that prints the surfer&amp;rsquo;s name and hometown.
  Create a method called cheer that will print &amp;ldquo;I totally rock man, no wipeouts!</description>
    </item>
    
    <item>
      <title>09. Traveling Companions  Part 2  👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-02/09-traveling-companion-part-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/09-traveling-companion-part-2/</guid>
      <description>Traveling Companions, Part 2 This is Part 2 of a three-part mini-project.
In this second part, you will examine the averages of each column and reduce the DataFrame to include only types of companion travelers that are above 1% across all three years.
Instructions  Your final table should align with the following table:  References Tourism Malaysia
 ✅ Solutions   Solutions Click Here    # Check the mean of the columns combined_travel_df.</description>
    </item>
    
    <item>
      <title>09. Var SDZ Score Review  👩‍🎓👨‍🎓</title>
      <link>/01-excel/activities/day-03/09-var-sdz-score-review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/09-var-sdz-score-review/</guid>
      <description>Variance, Standard Deviation and Z-Score Review It is now your turn to practice summarizing the variability of a data set using heart disease death rate data from the CDC. This data is unchanged from its source, and requires some cleaning before our calculations.
Instructions   Open the variance_review.xlsx workbook that contains your raw data.
  Since the dataset needs to be cleaned up, start with making a copy of the worksheet, which you will work on cleaning.</description>
    </item>
    
    <item>
      <title>09. View Room Queries 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-02/09-view-room-queries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/09-view-room-queries/</guid>
      <description>A View with a Roomful of Queries In this activity, you will work with a partner to practice your join and subquery skills, as well as build out a view.
Instructions   Write a query to get the number of copies of a film title that exist in the inventory. The results should look like those shown in the following image. Your challenge is to use a subquery (a query embedded within another query) instead of a join.</description>
    </item>
    
    <item>
      <title>10. </title>
      <link>/10-advanced-sql/activities/day-03/10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/10/</guid>
      <description></description>
    </item>
    
    <item>
      <title>10.  Rock Paper Scissors 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-01/10-rps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/10-rps/</guid>
      <description>Create a Rock, Paper, Scissors game that takes user input from the command line and plays against the computer.
Instructions   Using the notebook, take an input of r, p, or s for rock, paper, or scissors.
  Have the computer randomly pick one of these three choices.
  Compare the user&amp;rsquo;s input to the computer&amp;rsquo;s choice to determine if the user won, lost, or tied.
  Hint  Check out this Stack Overflow question for help with using the random module to select a value from a list.</description>
    </item>
    
    <item>
      <title>10. API Exceptions 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-02/10-api-exceptions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/10-api-exceptions/</guid>
      <description>API Exceptions Not every call placed to an API will return a result. In this activity, you will use try and except to handle errors from API calls.
Instructions   Loop through the characters in the list, and send a request to the Star Wars API.
  Create a try clause and an except clause. In the try clause, append the height, mass, and character name that is available in the Star Wars API to their respective lists.</description>
    </item>
    
    <item>
      <title>10. Comic Books CSV 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-01/10-comic-books-csv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/10-comic-books-csv/</guid>
      <description>In this activity, you will take a large CSV of books, read it into Jupyter Notebook by using Pandas, clean up the columns, and then write a modified DataFrame to a new CSV file.
This dataset is an expanded version of the Comic Books dataset from the British Library, which you’ve already worked with.
Instructions   Read in the comic books CSV by using Pandas.
  Remove unnecessary columns from the DataFrame so that only the following columns remain:</description>
    </item>
    
    <item>
      <title>10. Iterative Requests 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-01/10-iterative-requests/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/10-iterative-requests/</guid>
      <description>Iterative Requests In this activity, you will test your knowledge of iterative requests by looping through a list of movies and collecting data from the OMDB API on each movie.
Instructions   Consider the following list of movie titles.
movies = [&amp;#34;Aliens&amp;#34;, &amp;#34;Sing&amp;#34;, &amp;#34;Moana&amp;#34;]   Make a request to the OMDb API for each movie in the list. Then:
  Print the director of each movie
  Save the responses in another list</description>
    </item>
    
    <item>
      <title>10. Pypies  👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-01/10-pypies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/10-pypies/</guid>
      <description>Pies Pie Chart In this activity, you will create a pie chart that visualizes pie flavor preferences in the United States.
Instructions Using the starter file, create a pie chart that matches the following image:
  Include all of the lists provided in the starter file: pies, pie_votes, colors, explode.
  Display the popularity percentages to one decimal place.
  Include a shadow, and determine the starting angle so the exploded pie piece is in the middle left section of the pie.</description>
    </item>
    
    <item>
      <title>10. Quantiles Outliers Boxplots 👩‍🏫🧑‍🏫 </title>
      <link>/01-excel/activities/day-03/10-quantiles-outliers-boxplots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/10-quantiles-outliers-boxplots/</guid>
      <description>Wwe are characterizing a dataset, we need to be careful that our summary statistics don&amp;rsquo;t misrepresent the data.
  The biggest challenges in statistics is that real-world data is imperfect. Oftentimes, real-world data will contain extreme values that can skew our interpretations, especially when we try to describe the center of a dataset.
  We use quantiles to describe segments of a dataset.
  quantiles are the &amp;ldquo;cut points&amp;rdquo; that separate a sorted dataset into equal-sized fragments.</description>
    </item>
    
    <item>
      <title>10. Revisit Subquery 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-02/10-revisit-subquery/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/10-revisit-subquery/</guid>
      <description>-- Find how many people rented BLANKET BEVERLY  SELECT COUNT(*) FROM customer WHERE customer_id IN  (  SELECT customer_id  FROM payment  WHERE rental_id IN  (  SELECT rental_id  FROM rental  WHERE inventory_id IN  (  SELECT inventory_id  FROM inventory  WHERE film_id IN  (  SELECT film_id  FROM film  WHERE title = &amp;#39;BLANKET BEVERLY&amp;#39;  )  )  ) ); </description>
    </item>
    
    <item>
      <title>10. Splitting 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-01/10-splitting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/10-splitting/</guid>
      <description>Sub SimpleArrays():   &amp;#39; String Splitting Example  &amp;#39; ------------------------------------------  Dim Words() As String  Dim Shakespeare As String  Shakespeare = &amp;#34;To be or not to be. That is the question&amp;#34;   &amp;#39; Break apart the Shakespeare quote into individual words  Words = Split(Shakespeare, &amp;#34; &amp;#34;)   &amp;#39; Print individual word  MsgBox (Words(5))  End Sub </description>
    </item>
    
    <item>
      <title>10. SQL Alchemy Revisited 👩‍🏫🧑‍🏫</title>
      <link>/10-advanced-sql/activities/day-01/10-sql-alchemy-revisited/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/10-sql-alchemy-revisited/</guid>
      <description># Dependencies # ---------------------------------- # Imports the method used for connecting to DBs from sqlalchemy import create_engine  # Imports the methods needed to abstract classes into tables from sqlalchemy.ext.declarative import declarative_base  # Allow us to declare column types from sqlalchemy import Column, Integer, String, Float  # Create Dog and Cat Classes # ----------------------------------  # Sets an object to utilize the default declarative base in SQL Alchemy Base = declarative_base()  # Creates Classes which will serve as the anchor points for our Tables class Dog(Base):  __tablename__ = &amp;#39;dog&amp;#39;  id = Column(Integer, primary_key=True)  name = Column(String(255))  color = Column(String(255))  age = Column(Integer)   class Cat(Base):  __tablename__ = &amp;#39;cat&amp;#39;  id = Column(Integer, primary_key=True)  name = Column(String(255))  color = Column(String(255))  age = Column(Integer)  # Create a Specific Instance of the Dog and Cat classes # ----------------------------------  # Calls the Pet Constructors to create &amp;#34;Dog&amp;#34; and &amp;#34;Cat&amp;#34; objects dog = Dog(name=&amp;#39;Rex&amp;#39;, color=&amp;#39;Brown&amp;#39;, age=4) cat = Cat(name=&amp;#34;Felix&amp;#34;, color=&amp;#34;Gray&amp;#34;, age=7)  # Create Database Connection # ---------------------------------- # Creates a connection to our DB engine = create_engine(&amp;#34;sqlite:///pets.</description>
    </item>
    
    <item>
      <title>10. Top Songs Pivot 👩‍🎓👨‍🎓</title>
      <link>/01-excel/activities/day-02/10-top-songs-pivot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/10-top-songs-pivot/</guid>
      <description>Top-Songs Pivot Table Solution you will be working toward is in the following image:
Pivot tables are exceptionally helpful when dealing with large-scale datasets that contain similarities between data points. For this activity, you will take a 5000-row spreadsheet containing data on the top-5000 songs from 1901 to today, and you’ll use pivot tables to figure out the artists with the most songs in the top 5000, what those songs are, and what year they came out.</description>
    </item>
    
    <item>
      <title>10. Traveling Companions  Part 3  👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-02/10-traveling-companion-part-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-02/10-traveling-companion-part-3/</guid>
      <description>Traveling Companions, Part 3 This is the third and final part of a three-part mini-project.
In this final part, you will take the DataFrame you created and, using Matplotlib, chart a comparison of three different countries for one type of traveling companion between 2016 and 2018.
Instructions   Check the comments in each cell of this Jupyter Notebook file for activity instructions.
  Your output should align with the following figure, depending on the user’s input variable:</description>
    </item>
    
    <item>
      <title>10. Unions 👩‍🏫🧑‍🏫</title>
      <link>/09-sql/activities/day-03/10-unions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/10-unions/</guid>
      <description>schema.sql DROP TABLE IF EXISTS toys; DROP TABLE IF EXISTS games;  CREATE TABLE toys (  toy_id SERIAL,  type VARCHAR,  name VARCHAR );  CREATE TABLE games (  game_id SERIAL,  type VARCHAR,  name VARCHAR );  INSERT INTO toys (type, name) VALUES (&amp;#39;sports&amp;#39;, &amp;#39;baseball&amp;#39;), (&amp;#39;adventure&amp;#39;, &amp;#39;staff&amp;#39;), (&amp;#39;sports&amp;#39;, &amp;#39;tennis ball&amp;#39;), (&amp;#39;fun&amp;#39;, &amp;#39;doll&amp;#39;);  INSERT INTO games (type, name) VALUES (&amp;#39;sports&amp;#39;, &amp;#39;tag&amp;#39;), (&amp;#39;adventure&amp;#39;, &amp;#39;Kings Quest&amp;#39;), (&amp;#39;sports&amp;#39;, &amp;#39;tennis&amp;#39;), (&amp;#39;fun&amp;#39;, &amp;#39;Make believe&amp;#39;); query.</description>
    </item>
    
    <item>
      <title>10. Write File  👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-02/10-write-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/10-write-file/</guid>
      <description># Dependencies import os import csv  # Specify the file to write to output_path = os.path.join(&amp;#34;.&amp;#34;, &amp;#34;output&amp;#34;, &amp;#34;new.csv&amp;#34;)   # Open the file using &amp;#34;write&amp;#34; mode. Specify the variable to hold the contents with open(output_path, &amp;#39;w&amp;#39;) as csvfile:   # Initialize csv.writer  csvwriter = csv.writer(csvfile, delimiter=&amp;#39;,&amp;#39;)   # Write the first row (column headers)  csvwriter.writerow([&amp;#39;First Name&amp;#39;, &amp;#39;Last Name&amp;#39;, &amp;#39;SSN&amp;#39;])   # Write the second row  csvwriter.</description>
    </item>
    
    <item>
      <title>10. Joins 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-01/10-joins/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-01/10-joins/</guid>
      <description>Joining Bird Bands When information could unintentionally be duplicated, data is often stored in separate tables with reference to an id. In the case of the dataset you will explore, most of the unique identifiers are labeled with the word code.
In this activity, you will be using joins to learn more about North American bird banding. The example contains data reduced from its original source, so if you would like to explore the data further, click the link in the Reference section.</description>
    </item>
    
    <item>
      <title>11. </title>
      <link>/10-advanced-sql/activities/day-03/11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-03/11/</guid>
      <description></description>
    </item>
    
    <item>
      <title>11.  Comic Books Summary 👩‍🎓👨‍🎓</title>
      <link>/04-pandas/activities/day-01/11-comic-books-summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04-pandas/activities/day-01/11-comic-books-summary/</guid>
      <description>In this activity, you use some of Pandas’ built-in functions to create a new summary DataFrame based on the modified version of the comic book DataFrame.
Instructions Using the modified DataFrame that was created earlier, create a summary table for the dataset that includes the following pieces of information:
  The count of unique authors within the DataFrame
  The count of unique countries of publication within the DataFrame</description>
    </item>
    
    <item>
      <title>11.  Loops 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-01/11-loops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/11-loops/</guid>
      <description># Loop through a range of numbers (0 through 4) for x in range(5):  print(x)  print(&amp;#34;-----------------------------------------&amp;#34;)  # Loop through a range of numbers (2 through 6 - yes 6! Up to, but not including, 7) for x in range(2, 7):  print(x)  print(&amp;#34;----------------------------------------&amp;#34;)   # Iterate through letters in a string word = &amp;#34;Peace&amp;#34; for letter in word:  print(letter) print(&amp;#34;----------------------------------------&amp;#34;)  # Iterate through a list zoo = [&amp;#34;cow&amp;#34;, &amp;#34;dog&amp;#34;, &amp;#34;bee&amp;#34;, &amp;#34;zebra&amp;#34;] for animal in zoo:  print(animal)  print(&amp;#34;----------------------------------------&amp;#34;)  # Loop while a condition is being met run = &amp;#34;y&amp;#34;  while run == &amp;#34;y&amp;#34;:  print(&amp;#34;Hi!</description>
    </item>
    
    <item>
      <title>11.  NYT API 👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-01/11-movie-loop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/11-movie-loop/</guid>
      <description> # Dependencies import requests from pprint import pprint from config import api_key  url = &amp;#34;https://api.nytimes.com/svc/search/v2/articlesearch.json?&amp;#34; # Search for articles that mention granola query = &amp;#34;granola&amp;#34; # Build query URL query_url = url + &amp;#34;api-key=&amp;#34; + api_key + &amp;#34;&amp;amp;q=&amp;#34; + query # Request articles articles = requests.get(query_url).json()  # The &amp;#34;response&amp;#34; property in articles contains the actual articles # list comprehension. articles_list = articles[&amp;#34;response&amp;#34;][&amp;#34;docs&amp;#34;] pprint(articles_list)  # Print the web_url of each stored article print(&amp;#34;Your Reading List&amp;#34;) for article in articles_list:  print(article[&amp;#34;web_url&amp;#34;])   </description>
    </item>
    
    <item>
      <title>11. Cereal Outliers 👩‍🎓👨‍🎓</title>
      <link>/01-excel/activities/day-03/11-cereal-outliers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/11-cereal-outliers/</guid>
      <description>Cereal Outliers In this activity, you will be investigating data from a dataset called 80 Cereals. Your task is to search through the ratings of each product and determine if there are any potential outliers in the dataset.
Instructions   Open up the activity workbook 11-Stu_CerealOutliers/Unsolved/Outliers_Activity_Unsolved.xlsx , and familiarize yourself with the raw data.
  Create a new worksheet, and name it &amp;ldquo;Outlier Testing&amp;rdquo;.
  In the &amp;ldquo;Outlier Testing&amp;rdquo; worksheet, create a summary statistics table of the rating for the following statistics:</description>
    </item>
    
    <item>
      <title>11. Lookups 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-02/11-lookups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/11-lookups/</guid>
      <description>VLOOKUP() takes in four values: a lookup value, the range of a table, the index number for a column within that range, and the match parameter.
  VLOOKUP() searches for a value, it is only looking for matches within the leftmost column of the range that they have selected.
  Since the formula listed specifies 3 as the column index, it will grab the value stored within the third column of the second table.</description>
    </item>
    
    <item>
      <title>11. Mine the Subquery 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-02/11-mine-the-subquery/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-02/11-mine-the-subquery/</guid>
      <description>Mine the Subqueries In this activity, you will continue to practice subqueries. Work individually or in pairs. You can use the ERD for help with the queries.
Instructions   Using subqueries, identify all actors who appear in the film ALTER VICTORY in the pagila database.
  Using subqueries, display the titles of films that the employee Jon Stephens rented to customers.
   ✅ Solutions   Solutions Click Here   SELECT first_name, last_name FROM actor WHERE actor_id IN (  SELECT actor_id  FROM film_actor  WHERE film_id IN  (  SELECT film_id  FROM film  WHERE title = &amp;#39;ALTER VICTORY&amp;#39;  ) );  -- Using subqueries, display the titles of films that were rented out by an employee named Jon Stephens.</description>
    </item>
    
    <item>
      <title>11. Scatter Plots 👩‍🏫🧑‍🏫</title>
      <link>/05-data-visualization/activities/day-01/11-scatter-plots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/11-scatter-plots/</guid>
      <description>%matplotlib notebook # Import Dependencies import random import matplotlib.pyplot as plt import numpy as np # The maximum x value for our chart will be 100 x_limit = 100  # List of values from 0 to 100 each value being 1 greater than the last x_axis = np.arange(0, x_limit, 1)  # Create a random array of data that we will use for our y values data = [random.</description>
    </item>
    
    <item>
      <title>11. Sentence Breaker 👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-01/11-sentence-breaker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/11-sentence-breaker/</guid>
      <description>Sentence Breaker Now, it’s your turn to create a macro by using the Split() function that identifies the n-th word in a user-provided sentence. This is a challenging assignment, so take your time on it. Try to work through it piece by piece.
Instructions The starter workbook has a cell containing a written sentence and several cells with numbers to identify the n-th word of the sentence.
The starter code provided in sentence_breaker.</description>
    </item>
    
    <item>
      <title>11. Surfer SQL 👩‍🎓👨‍🎓</title>
      <link>/10-advanced-sql/activities/day-01/11-surfer-sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/10-advanced-sql/activities/day-01/11-surfer-sql/</guid>
      <description>In today’s final activity, you will test your SQLAlchemy skills and update your Surfer database.
Instructions   Modify the Surfer class created during the previous activity so that it will function with SQLAlchemy. Use the following parameters:
  __tablename__ should be &amp;ldquo;surfers&amp;rdquo;.
  surfer_id should be an integer and the primary key.
  name should be a string capable of holding 255 characters.
  hometown should be a string capable of holding 255 characters.</description>
    </item>
    
    <item>
      <title>11. Unions 👩‍🎓👨‍🎓</title>
      <link>/09-sql/activities/day-03/11-unions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/09-sql/activities/day-03/11-unions/</guid>
      <description>In this activity, you will practice unions by combining data from tables without the use of joins.
Instructions   Using UNION, write a PostgreSQL statement to query the number of rows in tables city and country.
  Use UNION to display from the tables customer and customer_list the ID of all customers who live in the city of London. Determine whether both tables contain the same customers by using UNION ALL.</description>
    </item>
    
    <item>
      <title>11. World Bank API  👩‍🏫🧑‍🏫</title>
      <link>/06-python-apis/activities/day-02/11-world-bank-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/11-world-bank-api/</guid>
      <description># Dependencies import requests  url = &amp;#34;http://api.worldbank.org/v2/&amp;#34; api_format = &amp;#34;json&amp;#34;  # Get country information in JSON format countries_response = requests.get(f&amp;#34;{url}countries?format={api_format}&amp;#34;).json()  # First element is general information, second is countries themselves countries = countries_response[1] # Report the names for country in countries:  print(country[&amp;#34;name&amp;#34;]) </description>
    </item>
    
    <item>
      <title>11. Zip 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-02/11-zip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/11-zip/</guid>
      <description>import csv import os  # Three Lists indexes = [1, 2, 3, 4] employees = [&amp;#34;Michael&amp;#34;, &amp;#34;Dwight&amp;#34;, &amp;#34;Meredith&amp;#34;, &amp;#34;Kelly&amp;#34;] department = [&amp;#34;Boss&amp;#34;, &amp;#34;Sales&amp;#34;, &amp;#34;Sales&amp;#34;, &amp;#34;HR&amp;#34;]  # Zip all three lists together into tuples roster = zip(indexes, employees, department) print(roster)  # Print the contents of each row for employee in roster:  print(employee)  # save the output file path output_file = os.path.join(&amp;#34;./output/activity-11-output.csv&amp;#34;)  # open the output file, create a header row, and then write the zipped object to the csv with open(output_file, &amp;#34;w&amp;#34;) as datafile:  writer = csv.</description>
    </item>
    
    <item>
      <title>13. Choose your story  👩‍🎓👨‍🎓</title>
      <link>/02-vba/activities/day-01/13-choose-your-story/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/13-choose-your-story/</guid>
      <description>Choose Your Story In this activity, you will practice using conditionals by creating the first step of a role-playing adventure.
Instructions Create an Excel workbook and VBA macro that provides a user with an input field and a single button. Based on the user-input number (1, 2, 3, or 4), the button will trigger different message boxes as follows:
  If the user enters a value of 1, display “You choose to enter the wooded forest of doom!</description>
    </item>
    
    <item>
      <title>12.  Number Chain 👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-01/12-number-chain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-01/12-number-chain/</guid>
      <description>In this activity, you will take user input and print out a string of numbers.
Instructions   Using a while loop, ask the user &amp;ldquo;How many numbers?&amp;rdquo;, and then print out a chain of numbers in increasing order, from 0 to the user-input number.
  After the results have been printed, ask the user if they would like to continue.
  If &amp;ldquo;y&amp;rdquo; is entered, keep the chain running by inputting a new number and starting a new count from 0 to the new user-input number.</description>
    </item>
    
    <item>
      <title>12. Census Breakdown  👩‍🎓👨‍🎓</title>
      <link>/03-python/activities/day-02/12-census-breakdown/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/12-census-breakdown/</guid>
      <description>In this activity, you will be provided with a large dataset from the 2019 U.S. Census. Your task is to clean up this dataset and create a new CSV file that is easier to comprehend.
Instructions   Create a Python application that reads in the data from the 2019 U.S. Census.
  Then, store the contents of Place, Population, Per Capita Income, and Poverty Count into Python Lists.</description>
    </item>
    
    <item>
      <title>12. Conditionals 👩‍🏫🧑‍🏫</title>
      <link>/02-vba/activities/day-01/12-conditional/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02-vba/activities/day-01/12-conditional/</guid>
      <description>Sub Conditionals():   &amp;#39; Simple Conditional Example  &amp;#39; ------------------------------------------  If Range(&amp;#34;A2&amp;#34;).Value &amp;gt; Range(&amp;#34;B2&amp;#34;).Value Then  MsgBox (&amp;#34;Num 1 is greater than Num 2&amp;#34;)  End If   &amp;#39; Simple Conditional with If, Else, and Elseif  &amp;#39; ------------------------------------------  If Range(&amp;#34;A5&amp;#34;).Value &amp;gt; Range(&amp;#34;B5&amp;#34;).Value Then  MsgBox (&amp;#34;Num 3 is greater than Num 4&amp;#34;)   Elseif Range(&amp;#34;A5&amp;#34;).Value &amp;lt; Range(&amp;#34;B5&amp;#34;).Value Then  MsgBox(&amp;#34;Num 4 is greater than Num 3&amp;#34;)   Else  MsgBox(&amp;#34;Num 3 and Num 4 are equal&amp;#34;)   End If   &amp;#39; Conditional with Operators (And)  &amp;#39; ------------------------------------------  If (Range(&amp;#34;A8&amp;#34;).</description>
    </item>
    
    <item>
      <title>12. Product Pivot 👩‍🎓👨‍🎓</title>
      <link>/01-excel/activities/day-02/12-product-pivot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-02/12-product-pivot/</guid>
      <description>Production Pivot An independent artist who sells their designs on products in an online store has called upon you to create a table that visualizes the cost of their recent orders. Using lookups, create a pivot table for the artist , as captured in the following image:
Instructions   Determine the &amp;ldquo;Product Price&amp;rdquo; of each row in the &amp;ldquo;Orders&amp;rdquo; sheet by using a VLOOKUP() that references each row&amp;rsquo;s &amp;ldquo;Product ID.</description>
    </item>
    
    <item>
      <title>12. Retrieving Articles 👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-01/12-retrieving-articles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-01/12-retrieving-articles/</guid>
      <description>Retrieving Articles In this activity, you will create an application that grabs articles from the NYT API, stores them within a list, and prints snippets of the articles to the screen.
Instructions   Save the NYT API endpoint to a variable. Make sure that you include the right query parameter for retrieving JSON data!
  Register for and save your API Key to a variable.
  Decide on a search term, and save it to a variable.</description>
    </item>
    
    <item>
      <title>12. Scatter Py 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-01/12-scatterpy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/12-scatterpy/</guid>
      <description>Scatter Py In this activity, you will create a scatter plot that visualizes ice cream sales in comparison to temperature increases.
Instructions Create a scatter plot that matches the following image:
Bonus Create a new list called scoop_price, fill it with values, and then set it so that the size of the dots are set according to those values.
 ✅ Solutions   Solutions Click Here    %matplotlib notebook import matplotlib.</description>
    </item>
    
    <item>
      <title>12. Statistics Addon 👩‍🏫🧑‍🏫</title>
      <link>/01-excel/activities/day-03/12-statistics-addon/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/01-excel/activities/day-03/12-statistics-addon/</guid>
      <description>Excel is a fantastic tool for quickly accessing, manipulating, and visualizing small-to-medium-sized datasets. However, Excel does not contain many statistical algorithms or tests &amp;ldquo;out of the box.&amp;rdquo;
  As we progress through the curriculum, we will cover a number of more robust statistical functions, tests, and concepts.
  If we enable Excel&amp;rsquo;s Analysis ToolPak add-on, we can always return to Excel to perform statistical tests on smaller datasets.</description>
    </item>
    
    <item>
      <title>12. Two Calls👩‍🎓👨‍🎓</title>
      <link>/06-python-apis/activities/day-02/12-two-calls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/06-python-apis/activities/day-02/12-two-calls/</guid>
      <description>Lending Types In this activity, you’ll practice making two API calls in sequence. The second API call will depend on the response from the first.
Instructions   Retrieve a list of the lending types that the world bank keeps track of, and extract the ID key for each one.
  Next, determine how many countries are categorized under each lending type. Use a dictionary to store this information.</description>
    </item>
    
    <item>
      <title>13. Average Rain Bar Charts 👩‍🎓👨‍🎓</title>
      <link>/05-data-visualization/activities/day-01/13-avg-rain-bar-charts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/05-data-visualization/activities/day-01/13-avg-rain-bar-charts/</guid>
      <description>Average Rainfall In this activity, you will create a bar chart that shows the average rainfall in different states by importing data from a CSV file.
Instructions  Review the raw data (resources/avg_rain_state.csv) in the Resources folder. This dataset contains the average rainfall per state in any given year.  *Ggenerate a plot that shows the average rainfall per state, as per image below:
Hint   Think critically about the different plots we discussed today.</description>
    </item>
    
    <item>
      <title>13. Functions 👩‍🏫🧑‍🏫</title>
      <link>/03-python/activities/day-02/13-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/03-python/activities/day-02/13-functions/</guid>
      <description># Define the function and tell it to print &amp;#34;Hello!&amp;#34; when called def print_hello():  print(f&amp;#34;Hello!&amp;#34;)   # Call the function within the application to ensure the code is run print_hello() # -------------#  # Functions that take in and use parameters can also be defined def print_name(name):  print(&amp;#34;Hello &amp;#34; + name + &amp;#34;!&amp;#34;)   # When calling a function with a parameter, a parameter must be passed into the function print_name(&amp;#34;Bob Smith&amp;#34;) # -------------#  # The prime use case for functions is in being able to run the same code for different values list_one = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] list_two = [11, 12, 13, 14, 15]   def list_information(simple_list):  print(f&amp;#34;The values within the list are.</description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/01-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/01-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/02-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/02-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/03-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/03-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/04-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/04-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/05-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/05-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/06-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/06-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/07-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/07-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/08-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/08-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/09-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/09-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-01/10-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-01/10-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-02/01-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-02/01-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-02/02-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-02/02-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-02/03-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-02/03-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-02/04-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-02/04-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-03/01-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-03/01-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-03/02-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-03/02-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-03/03-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-03/03-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/15-mapping/activities/day-03/04-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/15-mapping/activities/day-03/04-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-02/01-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-02/01-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-02/02-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-02/02-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-02/03-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-02/03-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-02/04-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-02/04-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-02/05-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-02/05-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-02/06-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-02/06-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-02/07-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-02/07-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-03/01-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-03/01-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-03/02-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-03/02-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-03/03-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-03/03-/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/21-neural-network-deep-learning/activities/day-03/04-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/21-neural-network-deep-learning/activities/day-03/04-/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Credits</title>
      <link>/credits/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/credits/</guid>
      <description>Contributors Thanks to them for making Open Source Software a better place !
And a special thanks to @vjeantet for his work on docdock, a fork of hugo-theme-learn. v2.0.0 of this theme is inspired by his work.
Packages and libraries  mermaid - generation of diagram and flowchart from text in a similar manner as markdown font awesome - the iconic font and CSS framework jQuery - The Write Less, Do More, JavaScript Library lunr - Lunr enables you to provide a great search experience without the need for external, server-side, search services&amp;hellip; horsey - Progressive and customizable autocomplete component clipboard.</description>
    </item>
    
    <item>
      <title>Showcase</title>
      <link>/showcase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/showcase/</guid>
      <description>TAT by OVH Tshark.dev by Ross Jacobs inteliver by Amir Lavasani </description>
    </item>
    
  </channel>
</rss>
